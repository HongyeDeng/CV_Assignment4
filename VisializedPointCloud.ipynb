{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23aa4b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import laspy\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.cm as cm   \n",
    "import CSF\n",
    "from open3d.geometry import KDTreeSearchParamHybrid\n",
    "from open3d.geometry import PointCloud\n",
    "import os\n",
    "import io\n",
    "import contextlib\n",
    "import re\n",
    "import copy\n",
    "import pyvista as pv\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad8960b",
   "metadata": {},
   "source": [
    "# Visiualized the Pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569282fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pointcloud_file_path = r'PointClouds\\IntermediateFile\\non_ground.las'\n",
    "pointcloud_file_path = r'PointClouds\\PartB.las'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9da0e7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to read file: PointClouds\\IntermediateFile\\Roof.las\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'PointClouds\\\\IntermediateFile\\\\Roof.las'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 1. Read the LAS file using laspy.read()\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to read file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpointcloud_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m las \u001b[38;5;241m=\u001b[39m \u001b[43mlaspy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpointcloud_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile read successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 2. Extract coordinates (X, Y, Z)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# las.X, las.Y, las.Z provide the scaled (true) coordinates as floats\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\PointCloud\\Lib\\site-packages\\laspy\\lib.py:249\u001b[0m, in \u001b[0;36mread_las\u001b[1;34m(source, closefd, laz_backend, decompression_selection)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_las\u001b[39m(\n\u001b[0;32m    210\u001b[0m     source,\n\u001b[0;32m    211\u001b[0m     closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    212\u001b[0m     laz_backend\u001b[38;5;241m=\u001b[39mLazBackend\u001b[38;5;241m.\u001b[39mdetect_available(),\n\u001b[0;32m    213\u001b[0m     decompression_selection: DecompressionSelection \u001b[38;5;241m=\u001b[39m DecompressionSelection\u001b[38;5;241m.\u001b[39mall(),\n\u001b[0;32m    214\u001b[0m ):\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Entry point for reading las data in laspy\u001b[39;00m\n\u001b[0;32m    216\u001b[0m \n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m    Reads the whole file into memory.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;124;03m        The ``decompression_selection`` parameter.\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 249\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mopen_las\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosefd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlaz_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlaz_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecompression_selection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecompression_selection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m reader:\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\PointCloud\\Lib\\site-packages\\laspy\\lib.py:142\u001b[0m, in \u001b[0;36mopen_las\u001b[1;34m(source, mode, closefd, laz_backend, header, do_compress, encoding_errors, read_evlrs, decompression_selection)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LaspyException(\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_compress argument is not used when opening in read mode, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdid you meant to open in write mode ?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m     )\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(source, (\u001b[38;5;28mstr\u001b[39m, Path)):\n\u001b[1;32m--> 142\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(source, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m, closefd\u001b[38;5;241m=\u001b[39mclosefd)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(source, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m    144\u001b[0m     stream \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(source)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'PointClouds\\\\IntermediateFile\\\\Roof.las'"
     ]
    }
   ],
   "source": [
    "# 1. Read the LAS file using laspy.read()\n",
    "print(f\"Attempting to read file: {pointcloud_file_path}\")\n",
    "las = laspy.read(pointcloud_file_path)\n",
    "print(\"File read successfully.\")\n",
    "\n",
    "# 2. Extract coordinates (X, Y, Z)\n",
    "# las.X, las.Y, las.Z provide the scaled (true) coordinates as floats\n",
    "points = np.vstack((las.x, las.y, las.z)).transpose()\n",
    "print(f\"Extracted {points.shape[0]} points.\")\n",
    "\n",
    "# 3. Create an Open3D PointCloud object\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "# 4. Handle colors (if available in the LAS file)\n",
    "colors = None\n",
    "if 'red' in las.point_format.dimension_names and \\\n",
    "    'green' in las.point_format.dimension_names and \\\n",
    "    'blue' in las.point_format.dimension_names:\n",
    "    colors = np.vstack((las.red, las.green, las.blue)).transpose()\n",
    "    # Normalize colors from 0-65535 (16-bit) or 0-255 (8-bit) to 0-1 for Open3D\n",
    "    # if colors.max() > 255: # Check if it's 16-bit color data (common in LAS)\n",
    "    #     colors = colors / 65535.0\n",
    "    # else: # Assume 8-bit if max is <= 255, normalize accordingly\n",
    "    #     colors = colors / 255.0\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    print(\"Point cloud colored using RGB data from LAS file.\")\n",
    "elif 'intensity' in las.point_format.dimension_names:\n",
    "    intensities = las.intensity.astype(np.float32)\n",
    "\n",
    "    # Normalize intensities to the range [0, 1]\n",
    "    # This is crucial for applying a colormap correctly\n",
    "    if intensities.max() > intensities.min():\n",
    "        norm_intensities = (intensities - intensities.min()) / (intensities.max() - intensities.min())\n",
    "    else:\n",
    "        norm_intensities = np.zeros_like(intensities) # Handle case of uniform intensity\n",
    "\n",
    "    # Choose a Matplotlib colormap\n",
    "    # 'jet_r' goes from red (high) -> yellow -> green -> cyan -> blue (low)\n",
    "    # You can try others: 'viridis', 'plasma', 'inferno', 'magma', 'hot', 'cool', etc.\n",
    "    # Add '_r' to reverse it (e.g., 'hot_r' for cool colors to hot colors)\n",
    "    colormap = cm.get_cmap('jet_r')\n",
    "\n",
    "    # Map the normalized intensities to RGB colors using the colormap\n",
    "    # colormap returns RGBA, so we take the first 3 channels (RGB)\n",
    "    colors = colormap(norm_intensities)[:, :3]\n",
    "\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    print(\"Point cloud colored by intensity using a colormap.\")\n",
    "else:\n",
    "    # Default to a uniform gray color if no specific coloring is available\n",
    "    pcd.paint_uniform_color([0.7, 0.7, 0.7]) # Light gray color\n",
    "    print(\"Point cloud painted with a uniform gray color (no RGB or intensity data found for coloring).\")\n",
    "\n",
    "# --- New part for setting point size with o3d.visualization.draw() ---\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window(window_name=\"LAS Point Cloud (Programmatic Size)\", width=1024, height=768)\n",
    "\n",
    "# Create a rendering options object\n",
    "render_option = vis.get_render_option()\n",
    "\n",
    "# Set the point size\n",
    "# A larger number means larger points. Common values are 1, 2, 3, 5, 10.\n",
    "# Experiment to find what looks best for your data density and scale.\n",
    "render_option.point_size = 0.5 # Set your desired point size here (float)\n",
    "\n",
    "# Optionally, you can set background color, etc.\n",
    "# render_option.background_color = np.asarray([0.1, 0.1, 0.1]) # Dark gray background\n",
    "\n",
    "vis.add_geometry(pcd)\n",
    "vis.run() # This starts the visualization loop\n",
    "vis.destroy_window()\n",
    "print(\"Visualization closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac263096",
   "metadata": {},
   "source": [
    "# Visualized the Pointcloud Pyvista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcab32b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'PointClouds\\\\IntermediateFile_B\\\\Roof_Clusters.las'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m pointcloud_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPointClouds\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mIntermediateFile_B\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mRoof_Clusters.las\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#pointcloud_file_path = r'PointClouds\\offset_PartA.las'\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m las \u001b[38;5;241m=\u001b[39m \u001b[43mlaspy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpointcloud_file_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\PointCloud\\Lib\\site-packages\\laspy\\lib.py:249\u001b[0m, in \u001b[0;36mread_las\u001b[1;34m(source, closefd, laz_backend, decompression_selection)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_las\u001b[39m(\n\u001b[0;32m    210\u001b[0m     source,\n\u001b[0;32m    211\u001b[0m     closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    212\u001b[0m     laz_backend\u001b[38;5;241m=\u001b[39mLazBackend\u001b[38;5;241m.\u001b[39mdetect_available(),\n\u001b[0;32m    213\u001b[0m     decompression_selection: DecompressionSelection \u001b[38;5;241m=\u001b[39m DecompressionSelection\u001b[38;5;241m.\u001b[39mall(),\n\u001b[0;32m    214\u001b[0m ):\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Entry point for reading las data in laspy\u001b[39;00m\n\u001b[0;32m    216\u001b[0m \n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m    Reads the whole file into memory.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;124;03m        The ``decompression_selection`` parameter.\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 249\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mopen_las\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosefd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlaz_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlaz_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecompression_selection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecompression_selection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m reader:\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\PointCloud\\Lib\\site-packages\\laspy\\lib.py:142\u001b[0m, in \u001b[0;36mopen_las\u001b[1;34m(source, mode, closefd, laz_backend, header, do_compress, encoding_errors, read_evlrs, decompression_selection)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LaspyException(\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_compress argument is not used when opening in read mode, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdid you meant to open in write mode ?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m     )\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(source, (\u001b[38;5;28mstr\u001b[39m, Path)):\n\u001b[1;32m--> 142\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(source, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m    144\u001b[0m     stream \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(source)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'PointClouds\\\\IntermediateFile_B\\\\Roof_Clusters.las'"
     ]
    }
   ],
   "source": [
    "# ---------- Step 1: Load LAS File ----------\n",
    "pointcloud_file_path = r'PointClouds\\IntermediateFile_B\\B_smooth_non_ground.las'\n",
    "#pointcloud_file_path = r'PointClouds\\offset_PartA.las'\n",
    "las = laspy.read(pointcloud_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53cbfe77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vettel\\AppData\\Local\\Temp\\ipykernel_18912\\1443409901.py:16: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap = cm.get_cmap(\"viridis\")  # or 'jet', 'plasma', etc.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48565e56bb240fe93514cef92954adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:50275/index.html?ui=P_0x2651cc4ca50_1&reconnect=auto\" class=\"pyvis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "las_x = las.X\n",
    "las_y = las.Y \n",
    "las_z = las.Z \n",
    "\n",
    "points = np.vstack((las_x, las_y, las_z)).T.astype(np.float32)\n",
    "# Extract XYZ coordinates\n",
    "#points = np.vstack((las.X, las.Y, las.Z)).T.astype(np.float32)\n",
    "\n",
    "# ---------- Step 2: Normalize Z-values ----------\n",
    "z = points[:, 2]\n",
    "z_min, z_max = np.min(z), np.max(z)\n",
    "z_normalized = (z - z_min) / (z_max - z_min + 1e-8)  # Avoid divide by zero\n",
    "\n",
    "# ---------- Step 3: Apply Colormap ----------\n",
    "# Use matplotlib colormap to get RGB colors\n",
    "cmap = cm.get_cmap(\"viridis\")  # or 'jet', 'plasma', etc.\n",
    "colors = cmap(z_normalized)[:, :3]  # Drop alpha\n",
    "\n",
    "# ---------- Step 4: Create PyVista Point Cloud ----------\n",
    "cloud = pv.PolyData(points)\n",
    "cloud[\"colors\"] = (colors * 255).astype(np.uint8)  # convert to 0–255\n",
    "\n",
    "# ---------- Step 5: Visualize ----------\n",
    "plotter = pv.Plotter()\n",
    "plotter.add_axes()\n",
    "plotter.set_background(\"white\")\n",
    "plotter.add_points(cloud, scalars=\"colors\", rgb=True, point_size=5, render_points_as_spheres=True)\n",
    "plotter.show(window_size=[1024, 768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a226bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad964eb9a4ca4fcbb420ee51a41a5ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:62089/index.html?ui=P_0x18b22210790_14&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------- Load first LAS file ----------\n",
    "las1 = laspy.read(r\"PointClouds\\IntermediateFile\\smooth_non_ground.las\")\n",
    "points1 = np.vstack((las1.X, las1.Y, las1.Z)).T.astype(np.float32)\n",
    "\n",
    "cloud1 = pv.PolyData(points1)\n",
    "cloud1['rgb'] = np.tile([0, 255, 0], (points1.shape[0], 1))  # Red\n",
    "\n",
    "# ---------- Load second LAS file ----------\n",
    "las2 = laspy.read(r\"PointClouds\\IntermediateFile\\rough_non_ground.las\")\n",
    "points2 = np.vstack((las2.X, las2.Y, las2.Z)).T.astype(np.float32)\n",
    "\n",
    "cloud2 = pv.PolyData(points2)\n",
    "cloud2['rgb'] = np.tile([255, 0, 0], (points2.shape[0], 1))  # Green\n",
    "\n",
    "# ---------- Plot both clouds ----------\n",
    "plotter = pv.Plotter()\n",
    "plotter.add_points(cloud1, scalars='rgb', rgb=True, point_size=3, render_points_as_spheres=True)\n",
    "plotter.add_points(cloud2, scalars='rgb', rgb=True, point_size=3, render_points_as_spheres=True)\n",
    "plotter.show(window_size=[1024, 768])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa49291f",
   "metadata": {},
   "source": [
    "# Visialized  las pcd at Same Window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8844b74",
   "metadata": {},
   "source": [
    "### o3d version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1352e97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z values normalized to range [0, 1]: min=0.0, max=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vettel\\AppData\\Local\\Temp\\ipykernel_9052\\4245619406.py:16: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap = cm.get_cmap('jet')\n"
     ]
    }
   ],
   "source": [
    "# -------- Load LAS file --------\n",
    "las_path = r\"PointClouds\\offset_PartA.las\"\n",
    "las = laspy.read(las_path)\n",
    "points_las = np.vstack((las.X, las.Y, las.Z)).T.astype(np.float32)\n",
    "\n",
    "pcd_las = o3d.geometry.PointCloud()\n",
    "pcd_las.points = o3d.utility.Vector3dVector(points_las)\n",
    "\n",
    "# Map Z values to colors\n",
    "z_values = points_las[:, 2]\n",
    "z_min, z_max = np.min(z_values), np.max(z_values)\n",
    "normalized_z = (z_values - z_min) / (z_max - z_min + 1e-8)  # Avoid division by zero\n",
    "print(f\"Z values normalized to range [0, 1]: min={normalized_z.min()}, max={normalized_z.max()}\")\n",
    "\n",
    "# Choose colormap (e.g., 'viridis', 'jet', etc.)\n",
    "cmap = cm.get_cmap('jet')\n",
    "colors = cmap(normalized_z)[:, :3]  # Drop alpha channel\n",
    "pcd_las.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "\n",
    "# -------- Load PCD file --------\n",
    "pcd_path = r\"PointClouds\\IntermediateFile\\Roof_clusters.pcd\"\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "# Apply scaling by multiplying XYZ\n",
    "points = np.asarray(pcd.points)\n",
    "scaled_points = points * 100.0 + 3.0\n",
    "pcd.points = o3d.utility.Vector3dVector(scaled_points)\n",
    "# Set all PCD points to yellow\n",
    "yellow_color = np.tile([1.0, 1.0, 0.0], (len(pcd.points), 1))\n",
    "pcd.colors = o3d.utility.Vector3dVector(yellow_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b8cbf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D WARNING] The number of points is 0 when creating axis-aligned bounding box.\n"
     ]
    }
   ],
   "source": [
    "# -------- Visualize Together with Point Size Control --------\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window(window_name=\"LAS + PCD Visualization\", width=1024, height=768)\n",
    "\n",
    "# Add LAS first (as requested)\n",
    "vis.add_geometry(pcd_las)\n",
    "vis.add_geometry(pcd)\n",
    "\n",
    "render_option = vis.get_render_option()\n",
    "render_option.point_size = 1.5  # Control point size here\n",
    "render_option.background_color = np.array([0.1, 0.1, 0.1]) \n",
    "# render_option.background_color = np.array([0.1, 0.1, 0.1])  # Optional: dark background\n",
    "\n",
    "vis.run()\n",
    "vis.destroy_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac253ed1",
   "metadata": {},
   "source": [
    "### PyVista Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3526d6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vettel\\AppData\\Local\\Temp\\ipykernel_18912\\4019420654.py:10: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  colors_las = (cm.get_cmap('viridis')(normalized_z)[:, :3] * 255).astype(np.uint8)\n"
     ]
    }
   ],
   "source": [
    "# -------- Load LAS file --------\n",
    "las_path = r\"PointClouds\\offset_PartA.las\"\n",
    "las = laspy.read(las_path)\n",
    "points_las = np.vstack((las.X, las.Y, las.Z)).T.astype(np.float32)\n",
    "\n",
    "# Map Z values to colors (jet colormap)\n",
    "z_values = points_las[:, 2]\n",
    "z_min, z_max = np.min(z_values), np.max(z_values)\n",
    "normalized_z = (z_values - z_min) / (z_max - z_min + 1e-8)\n",
    "colors_las = (cm.get_cmap('viridis')(normalized_z)[:, :3] * 255).astype(np.uint8)\n",
    "\n",
    "# Create PyVista point cloud from LAS\n",
    "cloud_las = pv.PolyData(points_las)\n",
    "cloud_las[\"RGB\"] = colors_las\n",
    "\n",
    "# -------- Load PCD file and scale --------\n",
    "pcd_path = r\"PointClouds\\IntermediateFile\\Roof_clusters.pcd\"\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "points_pcd = np.asarray(pcd.points)\n",
    "colors_pcd = np.asarray(pcd.colors)\n",
    "scaled_points = points_pcd * 100.0 + 10.0\n",
    "\n",
    "# Yellow color for PCD points\n",
    "#colors_pcd = np.tile([255, 255, 0], (len(scaled_points), 1)).astype(np.uint8)\n",
    "\n",
    "# Create PyVista point cloud from PCD\n",
    "cloud_pcd = pv.PolyData(scaled_points)\n",
    "cloud_pcd['RGB'] = (colors_pcd * 255).astype(np.uint8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "027bdf67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38d92abd5fa74ecdbc11e20e60f3f6ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:50275/index.html?ui=P_0x2650011b4d0_5&reconnect=auto\" class=\"pyvis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------- Visualization with PyVista --------\n",
    "plotter = pv.Plotter(notebook=True)\n",
    "plotter.add_points(cloud_las, scalars=\"RGB\", rgb=True, point_size=3, name=\"LAS Points\")\n",
    "plotter.add_points(cloud_pcd, scalars='RGB', rgb=True, point_size=5, name=\"PCD Points\")\n",
    "plotter.show(title=\"Interactive 3D View of LAS and PCD\", auto_close=False, window_size=[1024, 1024])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cd5f02",
   "metadata": {},
   "source": [
    "# Add Offset to Origin Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7776d888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File read successfully.\n",
      "Extracted 11405824 points.\n",
      "\n",
      "--- Full Point Cloud XY Range ---\n",
      "X Range: [0.00, 50000.00]\n",
      "Y Range: [0.00, 50000.00]\n",
      "---------------------------------\n",
      "33092\n"
     ]
    }
   ],
   "source": [
    "pointcloud_file_path = r'PointClouds\\offset_PartB.las'\n",
    "#pointcloud_file_path = r'PointClouds\\IntermediateFile_B\\B_smooth_non_ground.las'\n",
    "\n",
    "las = laspy.read(pointcloud_file_path)\n",
    "print(\"File read successfully.\")\n",
    "# 2. Extract coordinates (X, Y, Z)\n",
    "# las.X, las.Y, las.Z provide the scaled (true) coordinates as floats\n",
    "points = np.vstack((las.x, las.y, las.z)).transpose().astype(np.float32)\n",
    "print(f\"Extracted {points.shape[0]} points.\")\n",
    "                                        \n",
    "x_coords = las.X\n",
    "y_coords = las.Y\n",
    "z_coords = las.Z\n",
    "# 2. Get the range (min and max) of X and Y coordinates\n",
    "x_min, x_max = np.min(x_coords), np.max(x_coords)\n",
    "y_min, y_max = np.min(y_coords), np.max(y_coords)\n",
    "\n",
    "print(\"\\n--- Full Point Cloud XY Range ---\")\n",
    "print(f\"X Range: [{x_min:.2f}, {x_max:.2f}]\")\n",
    "print(f\"Y Range: [{y_min:.2f}, {y_max:.2f}]\")\n",
    "print(\"---------------------------------\")\n",
    "print(x_coords[500])\n",
    "\n",
    "output_file_path = r\"PointClouds\\offset_PartB.las\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7edfe522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Full Point Cloud XY Range ---\n",
      "X Range: [793000.00, 793500.00]\n",
      "Y Range: [385500.00, 386000.00]\n",
      "---------------------------------\n",
      "793322.3948387877\n",
      "322.39441745949443\n",
      "322.39441745949443\n",
      "\n",
      "Attempting to save offset data to: PointClouds\\offset_PartB.las\n",
      "Successfully saved offset point cloud to 'PointClouds\\offset_PartB.las'\n"
     ]
    }
   ],
   "source": [
    "# Extract X and Y coordinates for range calculation\n",
    "x_coords = las.x\n",
    "y_coords = las.y \n",
    "z_coords = las.z \n",
    "\n",
    "# 2. Get the range (min and max) of X and Y coordinates\n",
    "x_min, x_max = np.min(x_coords), np.max(x_coords)\n",
    "y_min, y_max = np.min(y_coords), np.max(y_coords)\n",
    "\n",
    "print(\"\\n--- Full Point Cloud XY Range ---\")\n",
    "print(f\"X Range: [{x_min:.2f}, {x_max:.2f}]\")\n",
    "print(f\"Y Range: [{y_min:.2f}, {y_max:.2f}]\")\n",
    "print(\"---------------------------------\")\n",
    "\n",
    "print(x_coords[20])\n",
    "offset_x = x_coords - x_min\n",
    "offset_y = y_coords - y_min\n",
    "print(offset_x[20])\n",
    "\n",
    "# Keep Z as is, or you could also apply an offset to Z if desired\n",
    "offset_z =  z_coords\n",
    "\n",
    "new_las = laspy.create(point_format=las.header.point_format, \n",
    "                           file_version=las.header.version)\n",
    "\n",
    "# Copy all other dimensions from the original LAS file to the new one\n",
    "# This ensures that attributes like intensity, classification, RGB colors, etc., are preserved\n",
    "for dim_name in las.point_format.dimension_names:\n",
    "    if dim_name not in ['x', 'y', 'z']: # Coordinates are handled separately\n",
    "        setattr(new_las, dim_name, getattr(las, dim_name))\n",
    "\n",
    "# Update header min/max values for the new offset data (important for correct visualization and tools)\n",
    "# laspy 2.0 automatically computes these on write, but explicit setting can be useful\n",
    "new_las.header.x_min = np.min(offset_x)\n",
    "new_las.header.x_max = np.max(offset_x)\n",
    "new_las.header.y_min = np.min(offset_y)\n",
    "new_las.header.y_max = np.max(offset_y)\n",
    "new_las.header.z_min = np.min(offset_z) # Z min/max won't change if Z wasn't offset\n",
    "new_las.header.z_max = np.max(offset_z)\n",
    "new_las.header.x_offset = 0.0\n",
    "new_las.header.y_offset = 0.0\n",
    "new_las.header.z_offset = 0.0\n",
    "#new_las.header.scales = [0.01, 0.01, 0.01]\n",
    "new_las.header.scales = [0.01, 0.01, 0.01]\n",
    "# Set the new offset coordinates\n",
    "# new_las.X = offset_x\n",
    "# new_las.Y = offset_y\n",
    "# new_las.Z = offset_z\n",
    "new_las.x = offset_x\n",
    "new_las.y = offset_y\n",
    "new_las.z = offset_z\n",
    "print(offset_x[20])\n",
    "\n",
    "# 5. Write the new LasData object to a new .las file\n",
    "print(f\"\\nAttempting to save offset data to: {output_file_path}\")\n",
    "new_las.write(output_file_path)\n",
    "print(f\"Successfully saved offset point cloud to '{output_file_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a4e016",
   "metadata": {},
   "source": [
    "# Crop the Origin Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0686984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pointcloud_file_path = r'PointClouds\\IntermediateFile_B\\B_non_ground.las'\n",
    "#output_file_path = r\"PointClouds\\cropped_PartB.las\" \n",
    "current_las = laspy.read(pointcloud_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5a7e3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current data X Range: [0.00, 50000.00]\n",
      "Current data Y Range: [0.00, 50000.00]\n",
      "Current data Z Range: [2500.00, 20486.00]\n",
      "\n",
      "Cropping points where X is between 0.00 and 10000.00\n",
      "And Y is between 0.00 and 10000.00\n",
      "Number of points after cropping: 123793\n",
      "\n",
      "Attempting to save cropped data to: PointClouds\\offset_PartB.las\n",
      "Successfully saved cropped point cloud to 'PointClouds\\offset_PartB.las'\n"
     ]
    }
   ],
   "source": [
    "point_data = {}\n",
    "for dim_name in current_las.point_format.dimension_names:\n",
    "    point_data[dim_name] = getattr(current_las, dim_name)\n",
    "\n",
    "current_x = point_data['X']\n",
    "current_y = point_data['Y']\n",
    "current_z = point_data['Z']\n",
    "\n",
    "# You can print the min/max of the current data to help set cropping thresholds\n",
    "print(f\"\\nCurrent data X Range: [{np.min(current_x):.2f}, {np.max(current_x):.2f}]\")\n",
    "print(f\"Current data Y Range: [{np.min(current_y):.2f}, {np.max(current_y):.2f}]\")\n",
    "print(f\"Current data Z Range: [{np.min(current_z):.2f}, {np.max(current_z):.2f}]\")\n",
    "\n",
    "\n",
    "# 2. Define the X and Y range for cropping\n",
    "# IMPORTANT: ADJUST THESE VALUES based on the area you want to crop.\n",
    "# These thresholds should be defined relative to the current (already offset) coordinates.\n",
    "# For instance, if your offset data now ranges from 0 to 500 in X and 0 to 600 in Y,\n",
    "# you might set thresholds like:\n",
    "crop_x_min = 0.0     # Example: Start from the new origin (0,0)\n",
    "crop_x_max = 10000.0   # Example: Crop up to 100 meters in X\n",
    "crop_y_min = 0.0     # Example: Start from the new origin (0,0)\n",
    "crop_y_max = 10000.0   # Example: Crop up to 100 meters in Y\n",
    "\n",
    "print(f\"\\nCropping points where X is between {crop_x_min:.2f} and {crop_x_max:.2f}\")\n",
    "print(f\"And Y is between {crop_y_min:.2f} and {crop_y_max:.2f}\")\n",
    "\n",
    "# 3. Crop points based on the defined X and Y ranges\n",
    "# Use boolean indexing on the current coordinates\n",
    "x_filter = (current_x >= crop_x_min) & (current_x <= crop_x_max)\n",
    "y_filter = (current_y >= crop_y_min) & (current_y <= crop_y_max)\n",
    "\n",
    "# Combine X and Y filters to get the indices of points to keep\n",
    "cropped_indices = np.where(x_filter & y_filter)[0]\n",
    "\n",
    "print(f\"Number of points after cropping: {len(cropped_indices)}\")\n",
    "\n",
    "if len(cropped_indices) == 0:\n",
    "    print(\"No points found within the specified cropping range. Output file will not be created.\")\n",
    "    exit() # Exit if no points are selected to avoid creating empty files\n",
    "\n",
    "# 4. Create a new LasData object for the cropped points\n",
    "# Use the header and point format from the current LAS file to maintain metadata\n",
    "# The header offsets of `current_las` should already be zeroed from the previous step.\n",
    "new_las = laspy.create(point_format=current_las.header.point_format,\n",
    "                        file_version=current_las.header.version)\n",
    "\n",
    "# Copy the header's offsets directly (they should be 0.0 from previous step)\n",
    "new_las.header.x_offset = current_las.header.x_offset\n",
    "new_las.header.y_offset = current_las.header.y_offset\n",
    "new_las.header.z_offset = current_las.header.z_offset\n",
    "\n",
    "# Copy the scale factors\n",
    "new_las.header.x_scale = current_las.header.x_scale\n",
    "new_las.header.y_scale = current_las.header.y_scale\n",
    "new_las.header.z_scale = current_las.header.z_scale\n",
    "\n",
    "# Assign the cropped floating-point coordinates\n",
    "new_las.X = current_x[cropped_indices]\n",
    "new_las.Y = current_y[cropped_indices]\n",
    "new_las.Z = current_z[cropped_indices]\n",
    "\n",
    "# Copy all other dimensions for the cropped points\n",
    "for dim_name in current_las.point_format.dimension_names:\n",
    "    # Skip X, Y, Z as they're handled above\n",
    "    if dim_name not in ['X', 'Y', 'Z']:\n",
    "        # Use getattr to get the original data for that dimension, then index by cropped_indices\n",
    "        setattr(new_las, dim_name, getattr(current_las, dim_name)[cropped_indices])\n",
    "\n",
    "# Update header min/max values for the *cropped* data\n",
    "# These will reflect the actual min/max of the points that remain after cropping.\n",
    "new_las.header.x_min = np.min(new_las.X)\n",
    "new_las.header.x_max = np.max(new_las.X)\n",
    "new_las.header.y_min = np.min(new_las.Y)\n",
    "new_las.header.y_max = np.max(new_las.Y)\n",
    "new_las.header.z_min = np.min(new_las.Z)\n",
    "new_las.header.z_max = np.max(new_las.Z)\n",
    "\n",
    "# 5. Write the new LasData object to a new .las file\n",
    "print(f\"\\nAttempting to save cropped data to: {output_file_path}\")\n",
    "new_las.write(output_file_path)\n",
    "print(f\"Successfully saved cropped point cloud to '{output_file_path}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9cd260",
   "metadata": {},
   "source": [
    "## Crop to 25 Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78a6b075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to read offset file: PointClouds\\IntermediateFile_B\\B_non_ground.las\n",
      "Offset file read successfully.\n",
      "\n",
      "Current data X Range: [0.00, 50000.00]\n",
      "Current data Y Range: [0.00, 50000.00]\n",
      "Current data Z Range: [2500.00, 20486.00]\n",
      "\n",
      "Dividing into 5 x 5 grid sections with a step of 10000.0.\n",
      "\n",
      "Processing section [0,0]:\n",
      "  X range: [0.00, 10000.00]\n",
      "  Y range: [0.00, 10000.00]\n",
      "  Number of points in this section: 123771\n",
      "  Saving section to: PointClouds\\B_non_ground_parts\\non_ground_cropped_part_00_00.las\n",
      "  Successfully saved 123771 points for section [0,0].\n",
      "\n",
      "Processing section [0,1]:\n",
      "  X range: [0.00, 10000.00]\n",
      "  Y range: [10000.00, 20000.00]\n",
      "  Number of points in this section: 275128\n",
      "  Saving section to: PointClouds\\B_non_ground_parts\\non_ground_cropped_part_00_01.las\n",
      "  Successfully saved 275128 points for section [0,1].\n",
      "\n",
      "Processing section [0,2]:\n",
      "  X range: [0.00, 10000.00]\n",
      "  Y range: [20000.00, 30000.00]\n",
      "  Number of points in this section: 335288\n",
      "  Saving section to: PointClouds\\B_non_ground_parts\\non_ground_cropped_part_00_02.las\n",
      "  Successfully saved 335288 points for section [0,2].\n",
      "\n",
      "Processing section [0,3]:\n",
      "  X range: [0.00, 10000.00]\n",
      "  Y range: [30000.00, 40000.00]\n",
      "  Number of points in this section: 251448\n",
      "  Saving section to: PointClouds\\B_non_ground_parts\\non_ground_cropped_part_00_03.las\n",
      "  Successfully saved 251448 points for section [0,3].\n",
      "\n",
      "Processing section [0,4]:\n",
      "  X range: [0.00, 10000.00]\n",
      "  Y range: [40000.00, 50000.00]\n",
      "  Number of points in this section: 211482\n",
      "  Saving section to: PointClouds\\B_non_ground_parts\\non_ground_cropped_part_00_04.las\n",
      "  Successfully saved 211482 points for section [0,4].\n",
      "\n",
      "Processing section [1,0]:\n",
      "  X range: [10000.00, 20000.00]\n",
      "  Y range: [0.00, 10000.00]\n",
      "  Number of points in this section: 197973\n",
      "  Saving section to: PointClouds\\B_non_ground_parts\\non_ground_cropped_part_01_00.las\n",
      "  Successfully saved 197973 points for section [1,0].\n",
      "\n",
      "Processing section [1,1]:\n",
      "  X range: [10000.00, 20000.00]\n",
      "  Y range: [10000.00, 20000.00]\n",
      "  Number of points in this section: 234240\n",
      "  Saving section to: PointClouds\\B_non_ground_parts\\non_ground_cropped_part_01_01.las\n",
      "  Successfully saved 234240 points for section [1,1].\n",
      "\n",
      "Processing section [1,2]:\n",
      "  X range: [10000.00, 20000.00]\n",
      "  Y range: [20000.00, 30000.00]\n",
      "  Number of points in this section: 370172\n",
      "  Saving section to: PointClouds\\B_non_ground_parts\\non_ground_cropped_part_01_02.las\n",
      "  Successfully saved 370172 points for section [1,2].\n",
      "\n",
      "Processing section [1,3]:\n",
      "  X range: [10000.00, 20000.00]\n",
      "  Y range: [30000.00, 40000.00]\n",
      "  Number of points in this section: 272372\n",
      "  Saving section to: PointClouds\\B_non_ground_parts\\non_ground_cropped_part_01_03.las\n",
      "  Successfully saved 272372 points for section [1,3].\n",
      "\n",
      "Processing section [1,4]:\n",
      "  X range: [10000.00, 20000.00]\n",
      "  Y range: [40000.00, 50000.00]\n",
      "  Number of points in this section: 295668\n",
      "  Saving section to: PointClouds\\B_non_ground_parts\\non_ground_cropped_part_01_04.las\n",
      "  Successfully saved 295668 points for section [1,4].\n",
      "\n",
      "Processing section [2,0]:\n",
      "  X range: [20000.00, 30000.00]\n",
      "  Y range: [0.00, 10000.00]\n",
      "  Number of points in this section: 235397\n",
      "  Saving section to: PointClouds\\B_non_ground_parts\\non_ground_cropped_part_02_00.las\n",
      "  Successfully saved 235397 points for section [2,0].\n",
      "\n",
      "Processing section [2,1]:\n",
      "  X range: [20000.00, 30000.00]\n",
      "  Y range: [10000.00, 20000.00]\n",
      "  Number of points in this section: 292110\n",
      "  Saving section to: PointClouds\\B_non_ground_parts\\non_ground_cropped_part_02_01.las\n",
      "  Successfully saved 292110 points for section [2,1].\n",
      "\n",
      "Processing section [2,2]:\n",
      "  X range: [20000.00, 30000.00]\n",
      "  Y range: [20000.00, 30000.00]\n",
      "  Number of points in this section: 395553\n",
      "  Saving section to: PointClouds\\B_non_ground_parts\\non_ground_cropped_part_02_02.las\n",
      "  Successfully saved 395553 points for section [2,2].\n",
      "\n",
      "Processing section [2,3]:\n",
      "  X range: [20000.00, 30000.00]\n",
      "  Y range: [30000.00, 40000.00]\n",
      "  Number of points in this section: 319607\n",
      "  Saving section to: PointClouds\\B_non_ground_parts\\non_ground_cropped_part_02_03.las\n",
      "  Successfully saved 319607 points for section [2,3].\n",
      "\n",
      "Processing section [2,4]:\n",
      "  X range: [20000.00, 30000.00]\n",
      "  Y range: [40000.00, 50000.00]\n",
      "  Number of points in this section: 224308\n",
      "  Saving section to: PointClouds\\B_non_ground_parts\\non_ground_cropped_part_02_04.las\n",
      "  Successfully saved 224308 points for section [2,4].\n",
      "\n",
      "Processing section [3,0]:\n",
      "  X range: [30000.00, 40000.00]\n",
      "  Y range: [0.00, 10000.00]\n",
      "  Number of points in this section: 210735\n",
      "  Saving section to: PointClouds\\B_non_ground_parts\\non_ground_cropped_part_03_00.las\n",
      "  Successfully saved 210735 points for section [3,0].\n",
      "\n",
      "Processing section [3,1]:\n",
      "  X range: [30000.00, 40000.00]\n",
      "  Y range: [10000.00, 20000.00]\n",
      "  Number of points in this section: 140942\n",
      "  Saving section to: PointClouds\\B_non_ground_parts\\non_ground_cropped_part_03_01.las\n",
      "  Successfully saved 140942 points for section [3,1].\n",
      "\n",
      "Processing section [3,2]:\n",
      "  X range: [30000.00, 40000.00]\n",
      "  Y range: [20000.00, 30000.00]\n",
      "  Number of points in this section: 275607\n",
      "  Saving section to: PointClouds\\B_non_ground_parts\\non_ground_cropped_part_03_02.las\n",
      "  Successfully saved 275607 points for section [3,2].\n",
      "\n",
      "Processing section [3,3]:\n",
      "  X range: [30000.00, 40000.00]\n",
      "  Y range: [30000.00, 40000.00]\n",
      "  Number of points in this section: 286137\n",
      "  Saving section to: PointClouds\\B_non_ground_parts\\non_ground_cropped_part_03_03.las\n",
      "  Successfully saved 286137 points for section [3,3].\n",
      "\n",
      "Processing section [3,4]:\n",
      "  X range: [30000.00, 40000.00]\n",
      "  Y range: [40000.00, 50000.00]\n",
      "  Number of points in this section: 295442\n",
      "  Saving section to: PointClouds\\B_non_ground_parts\\non_ground_cropped_part_03_04.las\n",
      "  Successfully saved 295442 points for section [3,4].\n",
      "\n",
      "Processing section [4,0]:\n",
      "  X range: [40000.00, 50000.00]\n",
      "  Y range: [0.00, 10000.00]\n",
      "  Number of points in this section: 157320\n",
      "  Saving section to: PointClouds\\B_non_ground_parts\\non_ground_cropped_part_04_00.las\n",
      "  Successfully saved 157320 points for section [4,0].\n",
      "\n",
      "Processing section [4,1]:\n",
      "  X range: [40000.00, 50000.00]\n",
      "  Y range: [10000.00, 20000.00]\n",
      "  Number of points in this section: 198201\n",
      "  Saving section to: PointClouds\\B_non_ground_parts\\non_ground_cropped_part_04_01.las\n",
      "  Successfully saved 198201 points for section [4,1].\n",
      "\n",
      "Processing section [4,2]:\n",
      "  X range: [40000.00, 50000.00]\n",
      "  Y range: [20000.00, 30000.00]\n",
      "  Number of points in this section: 316988\n",
      "  Saving section to: PointClouds\\B_non_ground_parts\\non_ground_cropped_part_04_02.las\n",
      "  Successfully saved 316988 points for section [4,2].\n",
      "\n",
      "Processing section [4,3]:\n",
      "  X range: [40000.00, 50000.00]\n",
      "  Y range: [30000.00, 40000.00]\n",
      "  Number of points in this section: 235391\n",
      "  Saving section to: PointClouds\\B_non_ground_parts\\non_ground_cropped_part_04_03.las\n",
      "  Successfully saved 235391 points for section [4,3].\n",
      "\n",
      "Processing section [4,4]:\n",
      "  X range: [40000.00, 50000.00]\n",
      "  Y range: [40000.00, 50000.00]\n",
      "  Number of points in this section: 249330\n",
      "  Saving section to: PointClouds\\B_non_ground_parts\\non_ground_cropped_part_04_04.las\n",
      "  Successfully saved 249330 points for section [4,4].\n"
     ]
    }
   ],
   "source": [
    "# Define the path to your already offset .las file\n",
    "input_file_path = os.path.join('PointClouds', 'IntermediateFile_B\\B_non_ground.las')\n",
    "# Output directory for the 25 cropped files\n",
    "output_dir = r\"PointClouds\\B_non_ground_parts\"\n",
    "os.makedirs(output_dir, exist_ok=True) # Ensure the output directory exists\n",
    "\n",
    "# 1. Read the already offset LAS file\n",
    "print(f\"Attempting to read offset file: {input_file_path}\")\n",
    "current_las = laspy.read(input_file_path)\n",
    "print(\"Offset file read successfully.\")\n",
    "\n",
    "# Get X, Y, Z coordinates and all other dimensions from the current LAS file\n",
    "point_data = {}\n",
    "for dim_name in current_las.point_format.dimension_names:\n",
    "    point_data[dim_name] = getattr(current_las, dim_name)\n",
    "\n",
    "current_x = point_data['X']\n",
    "current_y = point_data['Y']\n",
    "current_z = point_data['Z'] # Z is also needed for the new LAS file\n",
    "\n",
    "# You can print the min/max of the current data to help verify your understanding\n",
    "print(f\"\\nCurrent data X Range: [{np.min(current_x):.2f}, {np.max(current_x):.2f}]\")\n",
    "print(f\"Current data Y Range: [{np.min(current_y):.2f}, {np.max(current_y):.2f}]\")\n",
    "print(f\"Current data Z Range: [{np.min(current_z):.2f}, {np.max(current_z):.2f}]\")\n",
    "\n",
    "# Define the cropping parameters\n",
    "x_start_range = 0.0\n",
    "y_start_range = 0.0\n",
    "# User stated range 0-49999, so max value is just below 50000\n",
    "x_end_range = 50000.0 # Define the upper bound for the entire area to be covered\n",
    "y_end_range = 50000.0 # Define the upper bound for the entire area to be covered\n",
    "\n",
    "step_size = 10000.0 # Each X and Y step is 10000 units\n",
    "\n",
    "# Calculate the number of divisions along X and Y\n",
    "# Add a small epsilon to ensure the upper bound is included if it's exactly on a multiple\n",
    "num_x_divisions = int(np.ceil((x_end_range - x_start_range) / step_size))\n",
    "num_y_divisions = int(np.ceil((y_end_range - y_start_range) / step_size))\n",
    "\n",
    "print(f\"\\nDividing into {num_x_divisions} x {num_y_divisions} grid sections with a step of {step_size}.\")\n",
    "\n",
    "# Loop through each section (grid cell)\n",
    "for i in range(num_x_divisions):\n",
    "    for j in range(num_y_divisions):\n",
    "        crop_x_min = x_start_range + i * step_size\n",
    "        crop_x_max = x_start_range + (i + 1) * step_size\n",
    "        crop_y_min = y_start_range + j * step_size\n",
    "        crop_y_max = y_start_range + (j + 1) * step_size\n",
    "\n",
    "        # Ensure max bounds do not exceed the overall end range (important for the last slice)\n",
    "        crop_x_max = min(crop_x_max, x_end_range)\n",
    "        crop_y_max = min(crop_y_max, y_end_range)\n",
    "\n",
    "        print(f\"\\nProcessing section [{i},{j}]:\")\n",
    "        print(f\"  X range: [{crop_x_min:.2f}, {crop_x_max:.2f}]\")\n",
    "        print(f\"  Y range: [{crop_y_min:.2f}, {crop_y_max:.2f}]\")\n",
    "\n",
    "        # 2. Crop points based on the defined X and Y ranges for the current section\n",
    "        x_filter = (current_x >= crop_x_min) & (current_x < crop_x_max) # Use < for upper bound to avoid overlap\n",
    "        y_filter = (current_y >= crop_y_min) & (current_y < crop_y_max) # Use < for upper bound\n",
    "\n",
    "        # Combine X and Y filters to get the indices of points to keep in this section\n",
    "        cropped_indices_section = np.where(x_filter & y_filter)[0]\n",
    "        \n",
    "        print(f\"  Number of points in this section: {len(cropped_indices_section)}\")\n",
    "\n",
    "        if len(cropped_indices_section) == 0:\n",
    "            print(f\"  Section [{i},{j}] contains no points. Skipping file creation.\")\n",
    "            continue # Skip to the next section if no points are found\n",
    "\n",
    "        # 3. Create a new LasData object for the cropped points of this section\n",
    "        new_las_section = laspy.create(point_format=current_las.header.point_format,\n",
    "                                        file_version=current_las.header.version)\n",
    "\n",
    "        # Copy the header's offsets directly (they should be 0.0 from previous offset step)\n",
    "        new_las_section.header.x_offset = current_las.header.x_offset\n",
    "        new_las_section.header.y_offset = current_las.header.y_offset\n",
    "        new_las_section.header.z_offset = current_las.header.z_offset\n",
    "\n",
    "        # Copy the scale factors\n",
    "        new_las_section.header.x_scale = current_las.header.x_scale\n",
    "        new_las_section.header.y_scale = current_las.header.y_scale\n",
    "        new_las_section.header.z_scale = current_las.header.z_scale\n",
    "\n",
    "        # Assign the cropped floating-point coordinates for this section\n",
    "        new_las_section.X = current_x[cropped_indices_section]\n",
    "        new_las_section.Y = current_y[cropped_indices_section]\n",
    "        new_las_section.Z = current_z[cropped_indices_section]\n",
    "\n",
    "        # Copy all other dimensions for the cropped points of this section\n",
    "        for dim_name in current_las.point_format.dimension_names:\n",
    "            if dim_name not in ['x', 'y', 'z']: # Skip X, Y, Z as they're handled above\n",
    "                setattr(new_las_section, dim_name, getattr(current_las, dim_name)[cropped_indices_section])\n",
    "\n",
    "        # Update header min/max values for the *cropped* data of this section\n",
    "        new_las_section.header.x_min = np.min(new_las_section.X)\n",
    "        new_las_section.header.x_max = np.max(new_las_section.X)\n",
    "        new_las_section.header.y_min = np.min(new_las_section.Y)\n",
    "        new_las_section.header.y_max = np.max(new_las_section.Y)\n",
    "        new_las_section.header.z_min = np.min(new_las_section.Z)\n",
    "        new_las_section.header.z_max = np.max(new_las_section.Z)\n",
    "\n",
    "        # 4. Define the output file name for this section\n",
    "        #section_output_file_name = f\"cropped_part_{i:02d}_{j:02d}.las\"\n",
    "        section_output_file_name = f\"non_ground_cropped_part_{i:02d}_{j:02d}.las\"\n",
    "        section_output_file_path = os.path.join(output_dir, section_output_file_name)\n",
    "\n",
    "        # Write the new LasData object to a new .las file for this section\n",
    "        print(f\"  Saving section to: {section_output_file_path}\")\n",
    "        new_las_section.write(section_output_file_path)\n",
    "        print(f\"  Successfully saved {len(cropped_indices_section)} points for section [{i},{j}].\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f90b694",
   "metadata": {},
   "source": [
    "# Cloth Simulate Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "27d142ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File read successfully.\n",
      "Extracted 378326 points.\n"
     ]
    }
   ],
   "source": [
    "#pointcloud_file_path = r'PointClouds\\cropped_parts\\cropped_part_00_01.las'\n",
    "pointcloud_file_path = r'PointClouds\\cropped_PartA.las'\n",
    "las = laspy.read(pointcloud_file_path)\n",
    "print(\"File read successfully.\")\n",
    "# 2. Extract coordinates (X, Y, Z)\n",
    "# las.X, las.Y, las.Z provide the scaled (true) coordinates as floats\n",
    "points = np.vstack((las.x, las.y, las.z)).transpose()\n",
    "print(f\"Extracted {points.shape[0]} points.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "054b72b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CSF filtering...\n",
      "CSF filtering complete.\n"
     ]
    }
   ],
   "source": [
    "csf = CSF.CSF()\n",
    "csf.params.bSloopSmooth = True        # Set to True for smoother results on steep slopes\n",
    "csf.params.cloth_resolution = 0.5    # Grid size of cloth. Smaller for finer detail.\n",
    "csf.params.class_threshold = 0.05      # Max distance from cloth to be classified as ground\n",
    "csf.params.rigidness = 3              # Rigidity of the cloth (1-3, 1 for soft, 3 for rigid)\n",
    "csf.params.iterations = 300           # Max iterations for cloth simulation\n",
    "\n",
    "csf.setPointCloud(points)\n",
    "# Variables to store indices of ground and non-ground points\n",
    "ground_indices = CSF.VecInt()\n",
    "non_ground_indices = CSF.VecInt()\n",
    "\n",
    "# Perform the filtering\n",
    "print(\"Starting CSF filtering...\")\n",
    "csf.do_filtering(ground_indices, non_ground_indices)\n",
    "print(\"CSF filtering complete.\")\n",
    "\n",
    "#csf.do_cloth_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68a2fbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ground points: 236900\n",
      "Number of non-ground points: 141426\n",
      "Opening Open3D visualization window...\n",
      "Visualization closed.\n"
     ]
    }
   ],
   "source": [
    "# Convert VecInt to NumPy arrays for easier indexing\n",
    "ground_indices_np = np.array(ground_indices)\n",
    "non_ground_indices_np = np.array(non_ground_indices)\n",
    "\n",
    "print(f\"Number of ground points: {len(ground_indices_np)}\")\n",
    "print(f\"Number of non-ground points: {len(non_ground_indices_np)}\")\n",
    "\n",
    "# 3. Create Open3D PointCloud objects for visualization\n",
    "# Assign different colors for ground and non-ground points\n",
    "\n",
    "# Ground points (Green)\n",
    "ground_pcd = o3d.geometry.PointCloud()\n",
    "if len(ground_indices_np) > 0:\n",
    "    ground_pcd.points = o3d.utility.Vector3dVector(points[ground_indices_np])\n",
    "    ground_pcd.paint_uniform_color([0, 1, 0])  # Green for ground points\n",
    "else:\n",
    "    print(\"No ground points found by CSF or an issue occurred during filtering.\")\n",
    "\n",
    "# Non-ground points (Red - for buildings/vegetation)\n",
    "non_ground_pcd = o3d.geometry.PointCloud()\n",
    "if len(non_ground_indices_np) > 0:\n",
    "    non_ground_pcd.points = o3d.utility.Vector3dVector(points[non_ground_indices_np])\n",
    "    non_ground_pcd.paint_uniform_color([1, 0, 0])  # Red for non-ground points\n",
    "else:\n",
    "    print(\"No non-ground points found by CSF or an issue occurred during filtering.\")\n",
    "\n",
    "\n",
    "# 4. Visualize the point clouds with Open3D\n",
    "print(\"Opening Open3D visualization window...\")\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window(window_name=\"Ground (Green) and Non-Ground (Red) Points (CSF Filtered)\", width=1024, height=768)\n",
    "\n",
    "render_option = vis.get_render_option()\n",
    "render_option.point_size = 0.5 # Adjust point size as desired for visualization\n",
    "# You can also set a background color if preferred:\n",
    "# render_option.background_color = np.asarray([0.1, 0.1, 0.1])\n",
    "\n",
    "if len(ground_indices_np) > 0:\n",
    "    vis.add_geometry(ground_pcd)\n",
    "if len(non_ground_indices_np) > 0:\n",
    "    vis.add_geometry(non_ground_pcd)\n",
    "\n",
    "vis.run() # This starts the interactive visualization loop\n",
    "vis.destroy_window()\n",
    "print(\"Visualization closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14a147ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78faf71b7c6458c8ce72faa6ab72e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:50275/index.html?ui=P_0x267b2f53790_24&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ground_pts = points[list(ground_indices)]\n",
    "nonground_pts = points[list(non_ground_indices)]\n",
    "\n",
    "# ---------- Step 3: Create PyVista Point Clouds ----------\n",
    "cloud_ground = pv.PolyData(ground_pts)\n",
    "cloud_nonground = pv.PolyData(nonground_pts)\n",
    "\n",
    "# ---------- Step 4: Visualize ----------\n",
    "plotter = pv.Plotter()\n",
    "plotter.add_axes()\n",
    "\n",
    "# Color the ground brown and non-ground blue\n",
    "plotter.add_points(cloud_ground, color=\"green\", point_size=5, render_points_as_spheres=True)\n",
    "plotter.add_points(cloud_nonground, color=\"red\", point_size=5, render_points_as_spheres=True)\n",
    "\n",
    "plotter.add_legend([\n",
    "    (\"Ground Points\", \"green\"),\n",
    "    (\"Non-Ground Points\", \"red\")\n",
    "])\n",
    "\n",
    "plotter.show(window_size=[800, 800])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a39593",
   "metadata": {},
   "source": [
    "## Visualized the Cloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5eef62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cloth with 1006009 points.\n"
     ]
    }
   ],
   "source": [
    "cloth_file = \"cloth_nodes.txt\"\n",
    "cloth_points = np.loadtxt(cloth_file)\n",
    "print(f\"Loaded cloth with {cloth_points.shape[0]} points.\")\n",
    "\n",
    "pointcloud_file_path = r'PointClouds\\cropped_parts\\cropped_part_00_01.las'\n",
    "#pointcloud_file_path = r'PointClouds\\cropped_partB.las'\n",
    "\n",
    "las = laspy.read(pointcloud_file_path)  # Replace with your LAS path\n",
    "las_points = np.vstack((las.X, las.Y, las.Z)).T.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7f34e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\PointCloud\\Lib\\site-packages\\pyvista\\core\\utilities\\points.py:77: UserWarning: Points is not a float type. This can cause issues when transforming or applying filters. Casting to ``np.float32``. Disable this by passing ``force_float=False``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb07404414a41a69971db68c7ff4319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:62089/index.html?ui=P_0x18a91b72b10_6&reconnect=auto\" class=\"pyvis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a PyVista point cloud for the LAS file\n",
    "las_cloud = pv.PolyData(las_points)\n",
    "las_cloud['Elevation'] = las_points[:, 2]  # Use Z for coloring\n",
    "\n",
    "# Create a PyVista point cloud for the cloth\n",
    "cloth_cloud = pv.PolyData(cloth_points)\n",
    "cloth_cloud['z'] = cloth_points[:, 2]\n",
    "\n",
    "# Set up the plotter\n",
    "plotter = pv.Plotter()\n",
    "plotter.add_mesh(las_cloud, render_points_as_spheres=True, point_size=3, scalars='Elevation', cmap='viridis', name='LAS')\n",
    "plotter.add_mesh(cloth_cloud, render_points_as_spheres=True, point_size=0.5, color='red', name='Cloth')\n",
    "\n",
    "plotter.add_axes()\n",
    "\n",
    "origin = np.array([las.X.min(), las.Y.min(), las.Z.min()])\n",
    "# Add custom labels near each axis end\n",
    "plotter.add_point_labels([origin + [1000, 0, 0]], [\"X\"], font_size=15, text_color='red')\n",
    "plotter.add_point_labels([origin + [0, 1000, 0]], [\"Y\"], font_size=15, text_color='green')\n",
    "plotter.add_point_labels([origin + [0, 0, 1000]], [\"Z\"], font_size=15, text_color='blue')\n",
    "\n",
    "plotter.show_grid()\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb90f094",
   "metadata": {},
   "source": [
    "## Save the Non_ground Pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea00b993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read original LAS file again to access all dimensions: PointClouds\\cropped_partB.las\n",
      "Using 83040 non-ground points for saving.\n",
      "\n",
      "Attempting to save non-ground points to: PointClouds\\non_ground_PartB.las\n",
      "Successfully saved non-ground point cloud to 'PointClouds\\non_ground_PartB.las'\n"
     ]
    }
   ],
   "source": [
    "output_non_ground_file_path = r\"PointClouds\\non_ground_PartB.las\"\n",
    "#input_file_for_all_dims_path = r'PointClouds\\cropped_parts\\cropped_part_00_01.las'\n",
    "input_file_for_all_dims_path = r'PointClouds\\cropped_partB.las'\n",
    "\n",
    "\n",
    "original_las = laspy.read(input_file_for_all_dims_path)\n",
    "print(f\"Read original LAS file again to access all dimensions: {input_file_for_all_dims_path}\")\n",
    "\n",
    "# Extract all XYZ points in the correct format for indexing\n",
    "xyz_points = np.vstack((original_las.X, original_las.Y, original_las.Z)).transpose()\n",
    "\n",
    "if 'non_ground_indices_np' not in locals():\n",
    "    print(\"WARNING: 'non_ground_indices_np' not found. Using a dummy selection for demonstration.\")\n",
    "    # This is a dummy selection, replace with your actual CSF output\n",
    "    num_points = original_las.header.number_of_points\n",
    "    all_indices = np.arange(num_points)\n",
    "    # Select 50% of points randomly as \"non-ground\" for demonstration\n",
    "    non_ground_indices_np = np.random.choice(all_indices, size=int(num_points * 0.5), replace=False)\n",
    "print(f\"Using {len(non_ground_indices_np)} non-ground points for saving.\")\n",
    "# --- END PLACEHOLDER ---\n",
    "\n",
    "# 1. Select the XYZ coordinates of the non-ground points\n",
    "non_ground_xyz = xyz_points[non_ground_indices_np]\n",
    "\n",
    "# 2. Create a new LasData object for only the non-ground points\n",
    "new_las = laspy.create(point_format=original_las.header.point_format,\n",
    "                        file_version=original_las.header.version)\n",
    "\n",
    "# 3. Set the new file's header offsets to 0.0 if you want a local coordinate system\n",
    "# This ensures that when this new file is read, its points are relative to (0,0,0)\n",
    "new_las.header.x_offset = 0.0\n",
    "new_las.header.y_offset = 0.0\n",
    "new_las.header.z_offset = 0.0\n",
    "\n",
    "# Keep the original scale factors for consistent precision\n",
    "new_las.header.x_scale = original_las.header.x_scale\n",
    "new_las.header.y_scale = original_las.header.y_scale\n",
    "new_las.header.z_scale = original_las.header.z_scale\n",
    "\n",
    "# 4. Assign the non-ground X, Y, Z coordinates to the new LasData object\n",
    "# Remember to use CAPITALIZED X, Y, Z for laspy's scaled coordinates!\n",
    "new_las.X = non_ground_xyz[:, 0]\n",
    "new_las.Y = non_ground_xyz[:, 1]\n",
    "new_las.Z = non_ground_xyz[:, 2]\n",
    "\n",
    "# 5. Copy all other non-XYZ dimensions for the non-ground points\n",
    "for dim_name in original_las.point_format.dimension_names:\n",
    "    if dim_name not in ['x', 'y', 'z']: # Skip X, Y, Z as they are handled above\n",
    "        # Retrieve the original data for this dimension, then select by non_ground_indices_np\n",
    "        setattr(new_las, dim_name, getattr(original_las, dim_name)[non_ground_indices_np])\n",
    "\n",
    "# 6. Update the new header's min/max bounds based on the non-ground data\n",
    "# This is important for correct display and metadata.\n",
    "new_las.header.x_min = np.min(new_las.X)\n",
    "new_las.header.x_max = np.max(new_las.X)\n",
    "new_las.header.y_min = np.min(new_las.Y)\n",
    "new_las.header.y_max = np.max(new_las.Y)\n",
    "new_las.header.z_min = np.min(new_las.Z)\n",
    "new_las.header.z_max = np.max(new_las.Z)\n",
    "\n",
    "# 7. Write the new LasData object to the output file\n",
    "print(f\"\\nAttempting to save non-ground points to: {output_non_ground_file_path}\")\n",
    "new_las.write(output_non_ground_file_path)\n",
    "print(f\"Successfully saved non-ground point cloud to '{output_non_ground_file_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f26696",
   "metadata": {},
   "source": [
    "# Calcualte Roughness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4eaff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_non_ground_file_path = r\"PointClouds\\non_ground_PartA.las\" \n",
    "input_non_ground_file_path = r\"PointClouds\\non_ground_PartB.las\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8f5f73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to read non-ground point cloud: PointClouds\\non_ground_PartB.las\n",
      "Non-ground file read successfully.\n",
      "Loaded 335288 non-ground points.\n",
      "No RGB data in non-ground file. Coloring uniformly.\n",
      "Calculating roughness for each non-ground point...\n",
      "Roughness calculation complete.\n"
     ]
    }
   ],
   "source": [
    "# 1. Read the non_ground LAS file\n",
    "print(f\"Attempting to read non-ground point cloud: {input_non_ground_file_path}\")\n",
    "las_data = laspy.read(input_non_ground_file_path)\n",
    "print(\"Non-ground file read successfully.\")\n",
    "\n",
    "# Get X, Y, Z coordinates\n",
    "xyz_points = np.vstack((las_data.X, las_data.Y, las_data.Z)).transpose()\n",
    "print(f\"Loaded {xyz_points.shape[0]} non-ground points.\")\n",
    "\n",
    "if xyz_points.shape[0] == 0:\n",
    "    print(\"No points found in the non-ground file. Cannot calculate roughness. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# Create an Open3D PointCloud object\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(xyz_points)\n",
    "\n",
    "# Optional: If colors exist, copy them for initial visualization or later use\n",
    "if 'red' in las_data.point_format.dimension_names and \\\n",
    "    'green' in las_data.point_format.dimension_names and \\\n",
    "    'blue' in las_data.point_format.dimension_names:\n",
    "    colors = np.vstack((las_data.red, las_data.green, las_data.blue)).transpose()\n",
    "    # Normalize colors to [0, 1] if they are 16-bit (0-65535) or 8-bit (0-255)\n",
    "    if colors.max() > 255: colors = colors / 65535.0\n",
    "    else: colors = colors / 255.0\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    print(\"Using original RGB colors from non-ground file.\")\n",
    "else:\n",
    "    pcd.paint_uniform_color([0.7, 0.7, 0.7]) # Default to light gray\n",
    "    print(\"No RGB data in non-ground file. Coloring uniformly.\")\n",
    "\n",
    "# 2. Calculate roughness for each point\n",
    "print(\"Calculating roughness for each non-ground point...\")\n",
    "# Use a KDTree for efficient nearest neighbor search\n",
    "pcd_tree = o3d.geometry.KDTreeFlann(pcd)\n",
    "\n",
    "# Number of neighbors to consider for roughness calculation\n",
    "# Adjust this parameter (k_neighbors) based on your point cloud density\n",
    "# A larger k will give a smoother estimate, a smaller k will capture finer detail.\n",
    "k_neighbors =  40\n",
    "\n",
    "roughness_values = np.zeros(xyz_points.shape[0])\n",
    "\n",
    "for i in range(xyz_points.shape[0]):\n",
    "    # Find k nearest neighbors for point i\n",
    "    # search_knn_vector_3d returns [k, list_of_indices, list_of_distances]\n",
    "    [k, idx, _] = pcd_tree.search_knn_vector_3d(pcd.points[i], k_neighbors)\n",
    "    \n",
    "    # Get the coordinates of the neighbors\n",
    "    neighbors = np.asarray(pcd.points)[idx, :]\n",
    "\n",
    "    # Compute the covariance matrix of the neighbors\n",
    "    # Need at least 2 points for covariance, ideally more than 3 for a robust plane estimate\n",
    "    if neighbors.shape[0] >= 3: \n",
    "        cov_matrix = np.cov(neighbors, rowvar=False) # rowvar=False means columns are variables (X,Y,Z)\n",
    "        \n",
    "        # Perform eigenvalue decomposition on the covariance matrix\n",
    "        # eigvalsh is for symmetric matrices, which covariance matrices are.\n",
    "        eigenvalues = np.linalg.eigvalsh(cov_matrix)\n",
    "        eigenvalues = np.sort(eigenvalues)[::-1] # Sort in descending order: lambda_1 >= lambda_2 >= lambda_3\n",
    "\n",
    "        # Roughness metric: ratio of the smallest eigenvalue to the sum of eigenvalues\n",
    "        # lambda_3 represents the variance perpendicular to the local plane.\n",
    "        # A smaller value means the points are more planar (smoother).\n",
    "        sum_eigenvalues = np.sum(eigenvalues)\n",
    "        if sum_eigenvalues > 1e-9: # Avoid division by zero for perfectly flat or identical points\n",
    "            roughness = eigenvalues[2] / sum_eigenvalues # roughness = lambda_3 / (lambda_1 + lambda_2 + lambda_3)\n",
    "        else:\n",
    "            roughness = 0.0 # Handle cases with no variance (e.g., all neighbors are the same point)\n",
    "\n",
    "        roughness_values[i] = roughness\n",
    "    else:\n",
    "        # If not enough neighbors for a robust covariance (e.g., edge cases)\n",
    "        roughness_values[i] = 0.0 \n",
    "\n",
    "print(\"Roughness calculation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c6cd7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Roughness values range: [0.000033, 0.310509]\n",
      "\n",
      "Dividing points with a roughness threshold of: 0.008000\n",
      "Number of 'smooth' non-ground points: 130273\n",
      "Number of 'rough' non-ground points: 205015\n",
      "Opening Open3D visualization window...\n",
      "Visualization closed.\n"
     ]
    }
   ],
   "source": [
    "# You can print min/max roughness to help set the threshold\n",
    "print(f\"\\nRoughness values range: [{np.min(roughness_values):.6f}, {np.max(roughness_values):.6f}]\")\n",
    "\n",
    "# 3. Define a roughness threshold to divide points\n",
    "# IMPORTANT: Adjust this 'roughness_threshold' value!\n",
    "# This threshold determines what you consider \"smooth\" vs. \"rough\".\n",
    "# Experiment with values based on the printed range above and visual inspection of your data.\n",
    "# A smaller threshold means more points will be classified as \"rough\".\n",
    "roughness_threshold = 0.008 # Example threshold: Tune this!\n",
    "\n",
    "print(f\"\\nDividing points with a roughness threshold of: {roughness_threshold:.6f}\")\n",
    "\n",
    "# Divide points into two sets based on the threshold\n",
    "smooth_indices = np.where(roughness_values <= roughness_threshold)[0]\n",
    "rough_indices = np.where(roughness_values > roughness_threshold)[0]\n",
    "\n",
    "print(f\"Number of 'smooth' non-ground points: {len(smooth_indices)}\")\n",
    "print(f\"Number of 'rough' non-ground points: {len(rough_indices)}\")\n",
    "\n",
    "# 4. Apply different colors for visualization\n",
    "smooth_pcd = pcd.select_by_index(list(smooth_indices))\n",
    "rough_pcd = pcd.select_by_index(list(rough_indices))\n",
    "\n",
    "smooth_pcd.paint_uniform_color([0, 0, 1]) # Blue for \"smooth\" non-ground points\n",
    "rough_pcd.paint_uniform_color([1, 0, 0])  # Red for \"rough\" non-ground points\n",
    "\n",
    "# 5. Visualize the point clouds\n",
    "print(\"Opening Open3D visualization window...\")\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window(window_name=f\"Non-Ground Roughness: Smooth (Blue) vs Rough (Red) (Threshold={roughness_threshold:.4f})\", \n",
    "                    width=1024, height=768)\n",
    "\n",
    "render_option = vis.get_render_option()\n",
    "render_option.point_size = 1.0 # Adjust point size as desired for visualization\n",
    "# render_option.background_color = np.asarray([0.1, 0.1, 0.1]) # Dark background\n",
    "\n",
    "# Add geometries only if they contain points\n",
    "if len(smooth_indices) > 0:\n",
    "    vis.add_geometry(smooth_pcd)\n",
    "if len(rough_indices) > 0:\n",
    "    vis.add_geometry(rough_pcd)\n",
    "\n",
    "vis.run()\n",
    "vis.destroy_window()\n",
    "print(\"Visualization closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ace500",
   "metadata": {},
   "source": [
    "### Visualized the Roughness Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c38e054",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vettel\\AppData\\Local\\Temp\\ipykernel_9052\\2432821284.py:10: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap = cm.get_cmap('jet')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025cf9adc962495ca53bb77a09067700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:53082/index.html?ui=P_0x1e0312b1c50_1&reconnect=auto\" class=\"pyvis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "las = laspy.read(input_non_ground_file_path)  # Replace with your LAS path\n",
    "las_points = np.vstack((las.X, las.Y, las.Z)).T.astype(np.float32)\n",
    "\n",
    "# --- Normalize roughness for color mapping ---\n",
    "rough_min = np.min(roughness_values)\n",
    "rough_max = np.max(roughness_values)\n",
    "rough_norm = (roughness_values - rough_min) / (rough_max - rough_min + 1e-8)\n",
    "\n",
    "# --- Apply colormap (e.g., viridis, jet) ---\n",
    "cmap = cm.get_cmap('jet')\n",
    "colors = cmap(rough_norm)[:, :3]  # Remove alpha\n",
    "colors = (colors * 255).astype(np.uint8)  # Convert to 0–255 for RGB\n",
    "\n",
    "# --- Create PyVista point cloud ---\n",
    "cloud = pv.PolyData(las_points)\n",
    "cloud['Roughness'] = roughness_values  # Store scalar roughness\n",
    "cloud['colors'] = colors  # RGB values\n",
    "\n",
    "# --- Visualize with PyVista ---\n",
    "plotter = pv.Plotter()\n",
    "plotter.add_axes()\n",
    "plotter.set_background(\"white\")\n",
    "\n",
    "# Option 1: Use RGB directly\n",
    "plotter.add_points(cloud, scalars='colors', rgb=True, point_size=4)\n",
    "\n",
    "# Option 2: Use scalar mapping (colorbar shows roughness)\n",
    "# plotter.add_points(cloud, scalars='Roughness', cmap='viridis', point_size=4, render_points_as_spheres=True)\n",
    "\n",
    "plotter.add_scalar_bar(title=\"Roughness\", n_labels=5, label_font_size=12)\n",
    "plotter.show(title=\"Roughness Visualization\", window_size=[1024, 768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f14cbb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b303f0c5d514f70b2f0974d66110b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:53082/index.html?ui=P_0x1e031337d10_2&reconnect=auto\" class=\"pyvis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Threshold\n",
    "roughness_threshold = 0.008\n",
    "\n",
    "# Split into mask for smooth and rough\n",
    "smooth_mask = roughness_values <= roughness_threshold\n",
    "rough_mask = roughness_values > roughness_threshold\n",
    "\n",
    "# Assign colors\n",
    "# Blue for smooth, Red for rough\n",
    "colors = np.zeros((len(las_points), 3), dtype=np.uint8)\n",
    "colors[smooth_mask] = [0, 0, 255]   # Blue\n",
    "colors[rough_mask] = [255, 0, 0]    # Red\n",
    "\n",
    "# Create PyVista PolyData\n",
    "cloud = pv.PolyData(las_points)\n",
    "cloud['colors'] = colors\n",
    "\n",
    "# Plot\n",
    "plotter = pv.Plotter()\n",
    "plotter.set_background(\"white\")\n",
    "plotter.add_axes()\n",
    "\n",
    "# Add points with RGB colors\n",
    "plotter.add_points(cloud, scalars='colors', rgb=True, point_size=4)\n",
    "plotter.show(title=\"Smooth (Blue) vs Rough (Red) Points\", window_size=[1024, 768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7aadcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read source LAS file for smooth points: PointClouds\\non_ground_PartB.las\n",
      "Using 130273 'smooth' points for saving.\n",
      "\n",
      "Attempting to save 'smooth' points to: PointClouds\\smooth_non_ground_PartB.las\n",
      "Successfully saved 'smooth' point cloud to 'PointClouds\\smooth_non_ground_PartB.las'\n"
     ]
    }
   ],
   "source": [
    "output_smooth_file_path = r\"PointClouds\\smooth_non_ground_PartB.las\"\n",
    "input_file_for_smooth_points_path = r\"PointClouds\\non_ground_PartB.las\"\n",
    "\n",
    "las_data_source = laspy.read(input_file_for_smooth_points_path)\n",
    "print(f\"Read source LAS file for smooth points: {input_file_for_smooth_points_path}\")\n",
    "\n",
    "# --- PLACEHOLDER FOR ROUGHNESS CALCULATION RESULT ---\n",
    "# In a full script, the 'smooth_indices' would be generated by your roughness calculation code.\n",
    "# For standalone demonstration, let's create some dummy indices.\n",
    "if 'smooth_indices' not in locals():\n",
    "    print(\"WARNING: 'smooth_indices' not found. Using a dummy selection for demonstration.\")\n",
    "    num_points_source = las_data_source.header.number_of_points\n",
    "    # Dummy: Select 20% of points randomly as \"smooth\" for demonstration\n",
    "    smooth_indices = np.random.choice(np.arange(num_points_source), \n",
    "                                        size=int(num_points_source * 0.2), \n",
    "                                        replace=False)\n",
    "    smooth_indices.sort() # Sorting is good practice but not strictly necessary for indexing\n",
    "print(f\"Using {len(smooth_indices)} 'smooth' points for saving.\")\n",
    "# --- END PLACEHOLDER ---\n",
    "\n",
    "if len(smooth_indices) == 0:\n",
    "    print(\"No smooth points found based on the threshold. No file will be created.\")\n",
    "    exit() # Exit if no smooth points are selected\n",
    "\n",
    "# 1. Create a new LasData object for only the smooth points\n",
    "# Use the header and point format from the source LAS file to maintain metadata structure\n",
    "new_las = laspy.create(point_format=las_data_source.header.point_format,\n",
    "                        file_version=las_data_source.header.version)\n",
    "\n",
    "# 2. Set the new file's header offsets to 0.0 (or copy from source if source was already zeroed)\n",
    "# This ensures consistency if the non_ground_points.las file already had its offsets at 0.0\n",
    "new_las.header.x_offset = las_data_source.header.x_offset\n",
    "new_las.header.y_offset = las_data_source.header.y_offset\n",
    "new_las.header.z_offset = las_data_source.header.z_offset\n",
    "\n",
    "# Copy the scale factors from the source\n",
    "new_las.header.x_scale = las_data_source.header.x_scale\n",
    "new_las.header.y_scale = las_data_source.header.y_scale\n",
    "new_las.header.z_scale = las_data_source.header.z_scale\n",
    "\n",
    "# 3. Assign the smooth X, Y, Z coordinates to the new LasData object\n",
    "# Remember to use CAPITALIZED X, Y, Z for laspy's scaled coordinates!\n",
    "new_las.X = las_data_source.X[smooth_indices]\n",
    "new_las.Y = las_data_source.Y[smooth_indices]\n",
    "new_las.Z = las_data_source.Z[smooth_indices]\n",
    "\n",
    "# 4. Copy all other non-XYZ dimensions for the smooth points\n",
    "for dim_name in las_data_source.point_format.dimension_names:\n",
    "    if dim_name not in ['x', 'y', 'z']: # Skip X, Y, Z as they are handled above\n",
    "        # Retrieve the original data for this dimension, then select by smooth_indices\n",
    "        setattr(new_las, dim_name, getattr(las_data_source, dim_name)[smooth_indices])\n",
    "\n",
    "# 5. Update the new header's min/max bounds based on the *actual* smooth data's range\n",
    "new_las.header.x_min = np.min(new_las.X)\n",
    "new_las.header.x_max = np.max(new_las.X)\n",
    "new_las.header.y_min = np.min(new_las.Y)\n",
    "new_las.header.y_max = np.max(new_las.Y)\n",
    "new_las.header.z_min = np.min(new_las.Z)\n",
    "new_las.header.z_max = np.max(new_las.Z)\n",
    "\n",
    "# 6. Write the new LasData object to the output file\n",
    "print(f\"\\nAttempting to save 'smooth' points to: {output_smooth_file_path}\")\n",
    "new_las.write(output_smooth_file_path)\n",
    "print(f\"Successfully saved 'smooth' point cloud to '{output_smooth_file_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5225cd44",
   "metadata": {},
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3716430b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to read file: PointClouds\\smooth_non_ground_PartA.las\n",
      "File read successfully.\n",
      "Loaded 94694 points.\n",
      "\n",
      "Performing DBSCAN clustering for connected components...\n",
      "DBSCAN found 182 clusters (components) and 2625 noise points.\n",
      "Components with fewer than 15 points will be colored gray.\n",
      "  Noise points (-1 label): 2625 points (will be gray)\n",
      "  Cluster 0: 4671 points (will be distinctly colored)\n",
      "  Cluster 1: 63 points (will be distinctly colored)\n",
      "  Cluster 2: 34 points (will be distinctly colored)\n",
      "  Cluster 3: 6634 points (will be distinctly colored)\n",
      "  Cluster 4: 193 points (will be distinctly colored)\n",
      "  Cluster 5: 1308 points (will be distinctly colored)\n",
      "  Cluster 6: 3237 points (will be distinctly colored)\n",
      "  Cluster 7: 3009 points (will be distinctly colored)\n",
      "  Cluster 8: 21 points (will be distinctly colored)\n",
      "  Cluster 9: 382 points (will be distinctly colored)\n",
      "  Cluster 10: 24 points (will be distinctly colored)\n",
      "  Cluster 11: 17741 points (will be distinctly colored)\n",
      "  Cluster 12: 91 points (will be distinctly colored)\n",
      "  Cluster 13: 19 points (will be distinctly colored)\n",
      "  Cluster 14: 15 points (will be distinctly colored)\n",
      "  Cluster 15: 23 points (will be distinctly colored)\n",
      "  Cluster 16: 51 points (will be distinctly colored)\n",
      "  Cluster 17: 22 points (will be distinctly colored)\n",
      "  Cluster 18: 43 points (will be distinctly colored)\n",
      "  Cluster 19: 28 points (will be distinctly colored)\n",
      "  Cluster 20: 39 points (will be distinctly colored)\n",
      "  Cluster 21: 209 points (will be distinctly colored)\n",
      "  Cluster 22: 129 points (will be distinctly colored)\n",
      "  Cluster 23: 87 points (will be distinctly colored)\n",
      "  Cluster 24: 140 points (will be distinctly colored)\n",
      "  Cluster 25: 449 points (will be distinctly colored)\n",
      "  Cluster 26: 84 points (will be distinctly colored)\n",
      "  Cluster 27: 25 points (will be distinctly colored)\n",
      "  Cluster 28: 55 points (will be distinctly colored)\n",
      "  Cluster 29: 25 points (will be distinctly colored)\n",
      "  Cluster 30: 23 points (will be distinctly colored)\n",
      "  Cluster 31: 74 points (will be distinctly colored)\n",
      "  Cluster 32: 8629 points (will be distinctly colored)\n",
      "  Cluster 33: 72 points (will be distinctly colored)\n",
      "  Cluster 34: 77 points (will be distinctly colored)\n",
      "  Cluster 35: 131 points (will be distinctly colored)\n",
      "  Cluster 36: 49 points (will be distinctly colored)\n",
      "  Cluster 37: 126 points (will be distinctly colored)\n",
      "  Cluster 38: 22 points (will be distinctly colored)\n",
      "  Cluster 39: 44 points (will be distinctly colored)\n",
      "  Cluster 40: 16 points (will be distinctly colored)\n",
      "  Cluster 41: 34 points (will be distinctly colored)\n",
      "  Cluster 42: 98 points (will be distinctly colored)\n",
      "  Cluster 43: 15 points (will be distinctly colored)\n",
      "  Cluster 44: 37 points (will be distinctly colored)\n",
      "  Cluster 45: 227 points (will be distinctly colored)\n",
      "  Cluster 46: 126 points (will be distinctly colored)\n",
      "  Cluster 47: 34 points (will be distinctly colored)\n",
      "  Cluster 48: 43 points (will be distinctly colored)\n",
      "  Cluster 49: 3173 points (will be distinctly colored)\n",
      "  Cluster 50: 303 points (will be distinctly colored)\n",
      "  Cluster 51: 58 points (will be distinctly colored)\n",
      "  Cluster 52: 69 points (will be distinctly colored)\n",
      "  Cluster 53: 146 points (will be distinctly colored)\n",
      "  Cluster 54: 20 points (will be distinctly colored)\n",
      "  Cluster 55: 248 points (will be distinctly colored)\n",
      "  Cluster 56: 4990 points (will be distinctly colored)\n",
      "  Cluster 57: 160 points (will be distinctly colored)\n",
      "  Cluster 58: 126 points (will be distinctly colored)\n",
      "  Cluster 59: 20 points (will be distinctly colored)\n",
      "  Cluster 60: 124 points (will be distinctly colored)\n",
      "  Cluster 61: 42 points (will be distinctly colored)\n",
      "  Cluster 62: 17 points (will be distinctly colored)\n",
      "  Cluster 63: 21 points (will be distinctly colored)\n",
      "  Cluster 64: 90 points (will be distinctly colored)\n",
      "  Cluster 65: 69 points (will be distinctly colored)\n",
      "  Cluster 66: 38 points (will be distinctly colored)\n",
      "  Cluster 67: 170 points (will be distinctly colored)\n",
      "  Cluster 68: 26 points (will be distinctly colored)\n",
      "  Cluster 69: 9633 points (will be distinctly colored)\n",
      "  Cluster 70: 202 points (will be distinctly colored)\n",
      "  Cluster 71: 27 points (will be distinctly colored)\n",
      "  Cluster 72: 39 points (will be distinctly colored)\n",
      "  Cluster 73: 54 points (will be distinctly colored)\n",
      "  Cluster 74: 86 points (will be distinctly colored)\n",
      "  Cluster 75: 46 points (will be distinctly colored)\n",
      "  Cluster 76: 61 points (will be distinctly colored)\n",
      "  Cluster 77: 2080 points (will be distinctly colored)\n",
      "  Cluster 78: 834 points (will be distinctly colored)\n",
      "  Cluster 79: 15 points (will be distinctly colored)\n",
      "  Cluster 80: 67 points (will be distinctly colored)\n",
      "  Cluster 81: 176 points (will be distinctly colored)\n",
      "  Cluster 82: 52 points (will be distinctly colored)\n",
      "  Cluster 83: 123 points (will be distinctly colored)\n",
      "  Cluster 84: 80 points (will be distinctly colored)\n",
      "  Cluster 85: 240 points (will be distinctly colored)\n",
      "  Cluster 86: 21 points (will be distinctly colored)\n",
      "  Cluster 87: 19 points (will be distinctly colored)\n",
      "  Cluster 88: 25 points (will be distinctly colored)\n",
      "  Cluster 89: 22 points (will be distinctly colored)\n",
      "  Cluster 90: 348 points (will be distinctly colored)\n",
      "  Cluster 91: 45 points (will be distinctly colored)\n",
      "  Cluster 92: 102 points (will be distinctly colored)\n",
      "  Cluster 93: 61 points (will be distinctly colored)\n",
      "  Cluster 94: 55 points (will be distinctly colored)\n",
      "  Cluster 95: 93 points (will be distinctly colored)\n",
      "  Cluster 96: 15 points (will be distinctly colored)\n",
      "  Cluster 97: 46 points (will be distinctly colored)\n",
      "  Cluster 98: 41 points (will be distinctly colored)\n",
      "  Cluster 99: 178 points (will be distinctly colored)\n",
      "  Cluster 100: 147 points (will be distinctly colored)\n",
      "  Cluster 101: 259 points (will be distinctly colored)\n",
      "  Cluster 102: 1421 points (will be distinctly colored)\n",
      "  Cluster 103: 2256 points (will be distinctly colored)\n",
      "  Cluster 104: 21 points (will be distinctly colored)\n",
      "  Cluster 105: 540 points (will be distinctly colored)\n",
      "  Cluster 106: 21 points (will be distinctly colored)\n",
      "  Cluster 107: 31 points (will be distinctly colored)\n",
      "  Cluster 108: 21 points (will be distinctly colored)\n",
      "  Cluster 109: 24 points (will be distinctly colored)\n",
      "  Cluster 110: 38 points (will be distinctly colored)\n",
      "  Cluster 111: 113 points (will be distinctly colored)\n",
      "  Cluster 112: 29 points (will be distinctly colored)\n",
      "  Cluster 113: 50 points (will be distinctly colored)\n",
      "  Cluster 114: 22 points (will be distinctly colored)\n",
      "  Cluster 115: 98 points (will be distinctly colored)\n",
      "  Cluster 116: 63 points (will be distinctly colored)\n",
      "  Cluster 117: 41 points (will be distinctly colored)\n",
      "  Cluster 118: 3063 points (will be distinctly colored)\n",
      "  Cluster 119: 15 points (will be distinctly colored)\n",
      "  Cluster 120: 219 points (will be distinctly colored)\n",
      "  Cluster 121: 15 points (will be distinctly colored)\n",
      "  Cluster 122: 442 points (will be distinctly colored)\n",
      "  Cluster 123: 432 points (will be distinctly colored)\n",
      "  Cluster 124: 41 points (will be distinctly colored)\n",
      "  Cluster 125: 816 points (will be distinctly colored)\n",
      "  Cluster 126: 1037 points (will be distinctly colored)\n",
      "  Cluster 127: 15 points (will be distinctly colored)\n",
      "  Cluster 128: 1239 points (will be distinctly colored)\n",
      "  Cluster 129: 155 points (will be distinctly colored)\n",
      "  Cluster 130: 16 points (will be distinctly colored)\n",
      "  Cluster 131: 109 points (will be distinctly colored)\n",
      "  Cluster 132: 231 points (will be distinctly colored)\n",
      "  Cluster 133: 43 points (will be distinctly colored)\n",
      "  Cluster 134: 61 points (will be distinctly colored)\n",
      "  Cluster 135: 243 points (will be distinctly colored)\n",
      "  Cluster 136: 25 points (will be distinctly colored)\n",
      "  Cluster 137: 15 points (will be distinctly colored)\n",
      "  Cluster 138: 84 points (will be distinctly colored)\n",
      "  Cluster 139: 26 points (will be distinctly colored)\n",
      "  Cluster 140: 134 points (will be distinctly colored)\n",
      "  Cluster 141: 314 points (will be distinctly colored)\n",
      "  Cluster 142: 18 points (will be distinctly colored)\n",
      "  Cluster 143: 62 points (will be distinctly colored)\n",
      "  Cluster 144: 25 points (will be distinctly colored)\n",
      "  Cluster 145: 18 points (will be distinctly colored)\n",
      "  Cluster 146: 23 points (will be distinctly colored)\n",
      "  Cluster 147: 21 points (will be distinctly colored)\n",
      "  Cluster 148: 27 points (will be distinctly colored)\n",
      "  Cluster 149: 21 points (will be distinctly colored)\n",
      "  Cluster 150: 32 points (will be distinctly colored)\n",
      "  Cluster 151: 70 points (will be distinctly colored)\n",
      "  Cluster 152: 3511 points (will be distinctly colored)\n",
      "  Cluster 153: 15 points (will be distinctly colored)\n",
      "  Cluster 154: 20 points (will be distinctly colored)\n",
      "  Cluster 155: 173 points (will be distinctly colored)\n",
      "  Cluster 156: 18 points (will be distinctly colored)\n",
      "  Cluster 157: 18 points (will be distinctly colored)\n",
      "  Cluster 158: 29 points (will be distinctly colored)\n",
      "  Cluster 159: 37 points (will be distinctly colored)\n",
      "  Cluster 160: 15 points (will be distinctly colored)\n",
      "  Cluster 161: 20 points (will be distinctly colored)\n",
      "  Cluster 162: 15 points (will be distinctly colored)\n",
      "  Cluster 163: 23 points (will be distinctly colored)\n",
      "  Cluster 164: 37 points (will be distinctly colored)\n",
      "  Cluster 165: 17 points (will be distinctly colored)\n",
      "  Cluster 166: 17 points (will be distinctly colored)\n",
      "  Cluster 167: 18 points (will be distinctly colored)\n",
      "  Cluster 168: 31 points (will be distinctly colored)\n",
      "  Cluster 169: 13 points (too small, will be gray)\n",
      "  Cluster 170: 10 points (too small, will be gray)\n",
      "  Cluster 171: 24 points (will be distinctly colored)\n",
      "  Cluster 172: 20 points (will be distinctly colored)\n",
      "  Cluster 173: 10 points (too small, will be gray)\n",
      "  Cluster 174: 19 points (will be distinctly colored)\n",
      "  Cluster 175: 16 points (will be distinctly colored)\n",
      "  Cluster 176: 15 points (will be distinctly colored)\n",
      "  Cluster 177: 18 points (will be distinctly colored)\n",
      "  Cluster 178: 22 points (will be distinctly colored)\n",
      "  Cluster 179: 23 points (will be distinctly colored)\n",
      "  Cluster 180: 21 points (will be distinctly colored)\n",
      "  Cluster 181: 18 points (will be distinctly colored)\n",
      "\n",
      "Opening Open3D visualization window for clustered components...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vettel\\AppData\\Local\\Temp\\ipykernel_18912\\2075394359.py:53: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap = cm.get_cmap('tab20', num_valid_clusters)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization closed.\n"
     ]
    }
   ],
   "source": [
    "input_file_path = r'PointClouds\\smooth_non_ground_PartA.las'\n",
    "\n",
    "# 1. Read the LAS file\n",
    "print(f\"Attempting to read file: {input_file_path}\")\n",
    "las_data = laspy.read(input_file_path)\n",
    "print(\"File read successfully.\")\n",
    "\n",
    "# Get X, Y, Z coordinates\n",
    "xyz_points = np.vstack((las_data.X, las_data.Y, las_data.Z)).transpose()\n",
    "print(f\"Loaded {xyz_points.shape[0]} points.\")\n",
    "\n",
    "if xyz_points.shape[0] == 0:\n",
    "    print(\"The input file contains no points. Cannot proceed with analysis. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# Create an Open3D PointCloud object\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(xyz_points)\n",
    "\n",
    "# 2. Perform Connected Component Analysis (using DBSCAN clustering as an approximation)\n",
    "# DBSCAN clusters points based on density. Points that are close to each other are grouped.\n",
    "print(\"\\nPerforming DBSCAN clustering for connected components...\")\n",
    "\n",
    "# DBSCAN parameters:\n",
    "# 'eps_distance': The maximum distance between two points for them to be considered neighbors.\n",
    "#                 This is critical for defining \"connectedness\". Tune this based on your point cloud's density.\n",
    "# 'min_cluster_points': The minimum number of points required to form a dense region (a cluster).\n",
    "#                 Smaller values yield more, smaller clusters.\n",
    "\n",
    "# You will likely need to tune these parameters for your specific data and scale!\n",
    "eps_distance = 100       # Example: 1.0 unit (e.g., meter) search radius\n",
    "min_cluster_points = 15  # Example: A cluster needs at least 10 points\n",
    "\n",
    "labels = np.array(pcd.cluster_dbscan(eps=eps_distance, min_points=min_cluster_points, print_progress=True))\n",
    "\n",
    "max_label = labels.max()\n",
    "# A label of -1 indicates noise points (points not assigned to any cluster)\n",
    "num_valid_clusters = max_label + 1 if max_label >= 0 else 0\n",
    "print(f\"DBSCAN found {num_valid_clusters} clusters (components) and {np.sum(labels == -1)} noise points.\")\n",
    "\n",
    "# 3. Filter Components by Point Number Threshold for visualization\n",
    "# Define the threshold for component size: components smaller than this will be colored gray.\n",
    "min_component_size_threshold = 15 # Example: Components with fewer than 50 points will be grayed out\n",
    "\n",
    "print(f\"Components with fewer than {min_component_size_threshold} points will be colored gray.\")\n",
    "\n",
    "# Create an array to store colors for all points, initialized to gray\n",
    "colors = np.full((xyz_points.shape[0], 3), 0.5) # Initialize all points to gray (RGB 0.5, 0.5, 0.5)\n",
    "\n",
    "# Prepare for distinct coloring of large components using a colormap\n",
    "# 'tab20' is a good categorical colormap for up to 20 distinct colors.\n",
    "# If you expect more, consider 'tab20b', 'tab20c', or 'hsv'.\n",
    "cmap = cm.get_cmap('tab20', num_valid_clusters) \n",
    "\n",
    "# Iterate through each unique cluster label\n",
    "for label in np.unique(labels):\n",
    "    component_indices = np.where(labels == label)[0]\n",
    "    component_size = len(component_indices)\n",
    "\n",
    "    if label == -1:\n",
    "        # Noise points are already gray from initialization, or you can assign a specific noise color\n",
    "        print(f\"  Noise points (-1 label): {component_size} points (will be gray)\")\n",
    "    elif component_size < min_component_size_threshold:\n",
    "        # Small component, will remain gray (as per initialization)\n",
    "        print(f\"  Cluster {label}: {component_size} points (too small, will be gray)\")\n",
    "    else:\n",
    "        # Large component, assign a distinct color from the colormap\n",
    "        colors[component_indices] = cmap(label)[:3] # Get RGB from colormap, discarding alpha\n",
    "        print(f\"  Cluster {label}: {component_size} points (will be distinctly colored)\")\n",
    "\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "# 4. Visualize the point cloud with component colors\n",
    "print(\"\\nOpening Open3D visualization window for clustered components...\")\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window(window_name=\"Point Cloud Components (Large: Color, Small/Noise: Gray)\", \n",
    "                    width=1024, height=768)\n",
    "\n",
    "render_option = vis.get_render_option()\n",
    "render_option.point_size = 8.0 # Adjust point size for better visibility\n",
    "# render_option.background_color = np.asarray([0.1, 0.1, 0.1]) # Optional: Dark background\n",
    "\n",
    "vis.add_geometry(pcd) # Add the point cloud with its assigned colors\n",
    "\n",
    "vis.run() # Starts the interactive visualization loop\n",
    "vis.destroy_window() # Closes the window when the user closes it\n",
    "print(\"Visualization closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "787614ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 48931 points belonging to clusters (excluding noise).\n",
      "Saving clustered (non-noise) points to: PointClouds\\clustered_PartA.las\n",
      "Successfully saved 48931 points to 'PointClouds\\clustered_PartA.las'\n"
     ]
    }
   ],
   "source": [
    "output_file_path = r'PointClouds\\clustered_PartA.las'\n",
    "\n",
    "clustered_indices = np.where(labels != -1)[0]\n",
    "print(f\"\\nFound {len(clustered_indices)} points belonging to clusters (excluding noise).\")\n",
    "\n",
    "if len(clustered_indices) > 0:\n",
    "    # Create a new LasData object for only the clustered points\n",
    "    new_las = laspy.create(point_format=las_data.header.point_format,\n",
    "                            file_version=las_data.header.version)\n",
    "\n",
    "    # Assign X, Y, Z coordinates for the clustered points\n",
    "    new_las.X = las_data.X[clustered_indices]\n",
    "    new_las.Y = las_data.Y[clustered_indices]\n",
    "    new_las.Z = las_data.Z[clustered_indices]\n",
    "\n",
    "    # Copy all other dimensions for the clustered points\n",
    "    for dim_name in las_data.point_format.dimension_names:\n",
    "        if dim_name not in ['x', 'y', 'z']:\n",
    "            # Use getattr and setattr to dynamically access and set dimensions\n",
    "            setattr(new_las, dim_name, getattr(las_data, dim_name)[clustered_indices])\n",
    "\n",
    "    # Update the new header's offsets and scale factors from the original\n",
    "    new_las.header.x_offset = las_data.header.x_offset\n",
    "    new_las.header.y_offset = las_data.header.y_offset\n",
    "    new_las.header.z_offset = las_data.header.z_offset\n",
    "    new_las.header.x_scale = las_data.header.x_scale\n",
    "    new_las.header.y_scale = las_data.header.y_scale\n",
    "    new_las.header.z_scale = las_data.header.z_scale\n",
    "\n",
    "    # Update the new header's min/max bounds based on the actual clustered data\n",
    "    new_las.header.x_min = np.min(new_las.X)\n",
    "    new_las.header.x_max = np.max(new_las.X)\n",
    "    new_las.header.y_min = np.min(new_las.Y)\n",
    "    new_las.header.y_max = np.max(new_las.Y)\n",
    "    new_las.header.z_min = np.min(new_las.Z)\n",
    "    new_las.header.z_max = np.max(new_las.Z)\n",
    "\n",
    "    # Write the new LasData object to the output file\n",
    "    print(f\"Saving clustered (non-noise) points to: {output_file_path}\")\n",
    "    new_las.write(output_file_path)\n",
    "    print(f\"Successfully saved {len(clustered_indices)} points to '{output_file_path}'\")\n",
    "else:\n",
    "    print(\"No points were identified as belonging to clusters. No file saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fed4f0",
   "metadata": {},
   "source": [
    "# RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "316a8768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n"
     ]
    }
   ],
   "source": [
    "input_file_path = r'PointClouds\\smooth_non_ground_PartA.las'\n",
    "# Load .las file using laspy\n",
    "las = laspy.read(input_file_path)\n",
    "points = np.vstack((las.X, las.Y, las.Z)).transpose()\n",
    "print(las.X.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdb8f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "affa53b18b8e4f72bfda8ddef68e358d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:60796/index.html?ui=P_0x2ef05d0db50_0&reconnect=auto\" class=\"pyvis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Prepare Open3D point cloud\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "# Optional: estimate normals\n",
    "pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=1, max_nn=10))\n",
    "\n",
    "max_planes = 20\n",
    "min_points_per_plane = 30\n",
    "distance_threshold = 100\n",
    "segments = []\n",
    "colors = []\n",
    "rest = pcd  # Start with full cloud\n",
    "\n",
    "for i in range(max_planes):\n",
    "    if len(rest.points) < min_points_per_plane or len(rest.points) < 3:\n",
    "        break\n",
    "\n",
    "    # RANSAC plane detection\n",
    "    plane_model, inliers = rest.segment_plane(\n",
    "        distance_threshold=distance_threshold,\n",
    "        ransac_n=5,\n",
    "        num_iterations=1000\n",
    "    )\n",
    "\n",
    "    if len(inliers) < min_points_per_plane:\n",
    "        break\n",
    "\n",
    "    plane_cloud = rest.select_by_index(inliers)\n",
    "    color = [random.random(), random.random(), random.random()]\n",
    "    segments.append(np.asarray(plane_cloud.points))\n",
    "    colors.append(np.tile(color, (len(plane_cloud.points), 1)))\n",
    "\n",
    "    rest = rest.select_by_index(inliers, invert=True)\n",
    "\n",
    "# Add remaining points as gray\n",
    "segments.append(np.asarray(rest.points))\n",
    "colors.append(np.tile([0.5, 0.5, 0.5], (len(rest.points), 1)))\n",
    "\n",
    "# Combine all segments\n",
    "all_points = np.vstack(segments)\n",
    "all_colors = np.vstack(colors)\n",
    "\n",
    "# Step 2: Visualize with PyVista\n",
    "cloud = pv.PolyData(all_points)\n",
    "cloud[\"colors\"] = all_colors\n",
    "\n",
    "plotter = pv.Plotter()\n",
    "plotter.add_mesh(cloud, scalars=\"colors\", rgb=True, point_size=5, render_points_as_spheres=True)\n",
    "plotter.add_axes()\n",
    "plotter.show(window_size=[800, 800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "210dfc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved segmented point cloud with color to: region_growing_colored_B.pcd\n"
     ]
    }
   ],
   "source": [
    "output_path = r'region_growing_colored_B.pcd'\n",
    "# Combine all segments into a single point cloud\n",
    "combined = o3d.geometry.PointCloud()\n",
    "for seg in segments:\n",
    "    combined += seg\n",
    "\n",
    "# Save to PCD file with color\n",
    "o3d.io.write_point_cloud(output_path, combined)\n",
    "print(f\"Saved segmented point cloud with color to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3e3e18",
   "metadata": {},
   "source": [
    "# Remove Point by Z-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92bddc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\PointCloud\\Lib\\site-packages\\pyvista\\core\\utilities\\points.py:77: UserWarning: Points is not a float type. This can cause issues when transforming or applying filters. Casting to ``np.float32``. Disable this by passing ``force_float=False``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8311fe4e993e4f82bef0a19ff1fe808c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:50275/index.html?ui=P_0x26548aa6590_22&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Step 1: Load LAS file ---\n",
    "input_path = r'PointClouds\\IntermediateFile_B\\B_non_ground.las'\n",
    "input_path = r'PointClouds\\cropped_PartA.las'\n",
    "las = laspy.read(input_path)\n",
    "\n",
    "# --- Step 2: Extract and filter points ---\n",
    "x, y, z = las.X, las.Y, las.Z\n",
    "points = np.vstack((x, y, z)).T\n",
    "\n",
    "# Set threshold\n",
    "z_threshold = 2500\n",
    "mask_above = z >= z_threshold\n",
    "mask_below = z < z_threshold\n",
    "\n",
    "# Combine mask to match original points\n",
    "color_array = np.zeros((len(z), 3))  # Initialize all black\n",
    "\n",
    "# Red for points above threshold\n",
    "color_array[mask_above] = [1.0, 0.0, 0.0]  # RGB red\n",
    "\n",
    "# Green for points below threshold\n",
    "color_array[mask_below] = [0.0, 1.0, 0.0]  # RGB green\n",
    "\n",
    "# --- Step 3: Create PyVista point cloud ---\n",
    "cloud = pv.PolyData(points)\n",
    "cloud[\"RGB\"] = (color_array * 255).astype(np.uint8)  # Convert to 0–255\n",
    "\n",
    "# --- Step 4: Visualize ---\n",
    "plotter = pv.Plotter()\n",
    "plotter.add_points(cloud, scalars=\"RGB\", rgb=True, point_size=5, render_points_as_spheres=True)\n",
    "plotter.add_axes()\n",
    "plotter.show(window_size=[800, 800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a9ad398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved filtered LAS to: PointClouds\\IntermediateFile_B\\B_non_ground_filtered.las\n"
     ]
    }
   ],
   "source": [
    "# --- Load LAS file ---\n",
    "las_path = r'PointClouds\\IntermediateFile_B\\B_non_ground.las'\n",
    "las_path = r'PointClouds\\offset_PartB.las'\n",
    "las = laspy.read(las_path)\n",
    "\n",
    "# --- Extract and filter points based on Z value ---\n",
    "x = las.X\n",
    "y = las.Y\n",
    "z = las.Z \n",
    "\n",
    "mask = z >= 2500.0  # Keep points with Z >= 10\n",
    "\n",
    "x_f = x[mask]\n",
    "y_f = y[mask]\n",
    "z_f = z[mask]\n",
    "\n",
    "# --- Create a new LAS header ---\n",
    "header = laspy.LasHeader(point_format=las.header.point_format, version=las.header.version)\n",
    "header.scales = las.header.scales\n",
    "header.offsets = las.header.offsets\n",
    "\n",
    "# --- Create new LAS object with filtered points ---\n",
    "filtered_las = laspy.LasData(header)\n",
    "# filtered_las.X = ((x_f - header.offsets[0]) / header.scales[0]).astype(np.int32)\n",
    "# filtered_las.Y = ((y_f - header.offsets[1]) / header.scales[1]).astype(np.int32)\n",
    "# filtered_las.Z = ((z_f - header.offsets[2]) / header.scales[2]).astype(np.int32)\n",
    "filtered_las.X = x_f.astype(np.int32)\n",
    "filtered_las.Y = y_f.astype(np.int32)\n",
    "filtered_las.Z = z_f.astype(np.int32)\n",
    "\n",
    "# Optional: copy additional attributes\n",
    "if 'intensity' in las.point_format.dimension_names:\n",
    "    filtered_las.intensity = las.intensity[mask]\n",
    "if 'classification' in las.point_format.dimension_names:\n",
    "    filtered_las.classification = las.classification[mask]\n",
    "\n",
    "# --- Save filtered point cloud ---\n",
    "output_path = r'PointClouds\\IntermediateFile_B\\B_non_ground_filtered.las'\n",
    "filtered_las.write(output_path)\n",
    "print(f\"Saved filtered LAS to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PointCloud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
